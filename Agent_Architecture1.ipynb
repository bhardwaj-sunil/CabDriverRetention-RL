{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cab-Driver Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from collections import deque\n",
    "import collections\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "# for building DQN model\n",
    "from keras import layers\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# for plotting graphs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import the environment\n",
    "from Env import CabDriver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the Time Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the time matrix provided\n",
    "Time_matrix = np.load(\"TM.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check what the max, min and mean time values are. This will help us in defining the 'next_step' function in the Environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "11.0\n",
      "0.0\n",
      "3.0542857142857143\n",
      "7.93705306122449\n"
     ]
    }
   ],
   "source": [
    "print(type(Time_matrix))\n",
    "print(Time_matrix.max())\n",
    "print(Time_matrix.min())\n",
    "print(Time_matrix.mean())\n",
    "print(Time_matrix.var())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Since the max time is 11 hours between any 2 points, the next state of the cab driver may increase at most by  1 day."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Agent Class\n",
    "\n",
    "If you are using this framework, you need to fill the following to complete the following code block:\n",
    "1. State and Action Size\n",
    "2. Hyperparameters\n",
    "3. Create a neural-network model in function 'build_model()'\n",
    "4. Define epsilon-greedy strategy in function 'get_action()'\n",
    "5. Complete the function 'append_sample()'. This function appends the recent experience tuple <state, action, reward, new-state> to the memory\n",
    "6. Complete the 'train_model()' function with following logic:\n",
    "   - If the memory size is greater than mini-batch size, you randomly sample experiences from memory as per the mini-batch size and do the following:\n",
    "      - Initialise your input and output batch for training the model\n",
    "      - Calculate the target Q value for each sample: reward + gamma*max(Q(s'a,))\n",
    "      - Get Q(s', a) values from the last trained model\n",
    "      - Update the input batch as your encoded state and output batch as your Q-values\n",
    "      - Then fit your DQN model using the updated input and output batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        # Define size of state and action\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "\n",
    "        # Write here: Specify you hyper parameters for the DQN\n",
    "        self.discount_factor = 0.95\n",
    "        self.learning_rate = 0.01\n",
    "        self.epsilon = 1\n",
    "        self.epsilon_max = 1\n",
    "        self.epsilon_decay = -0.0005 #for 15k\n",
    "        #self.epsilon_decay = -0.00015 #for 20k\n",
    "        self.epsilon_min = 0.00001\n",
    "        \n",
    "        self.batch_size = 32\n",
    "\n",
    "        # create replay memory using deque\n",
    "        self.memory = deque(maxlen=2000)\n",
    "\n",
    "        # Initialize the value of the states tracked\n",
    "        self.states_tracked = []\n",
    "        \n",
    "        # We are going to track state [0,0,0] and action (0,2) at index 2 in the action space.\n",
    "        self.track_state = np.array(env.state_encod_arch1([0,0,0])).reshape(1, 36)\n",
    "\n",
    "        # create main model and target model\n",
    "        self.model = self.build_model()\n",
    "\n",
    "    # approximate Q function using Neural Network\n",
    "    def build_model(self):\n",
    "        \"\"\"\n",
    "        Function that takes in the agent and constructs the network\n",
    "        to train it\n",
    "        @return model\n",
    "        @params agent\n",
    "        \"\"\"\n",
    "        input_shape = self.state_size\n",
    "        model = Sequential()\n",
    "        # Write your code here: Add layers to your neural nets       \n",
    "        model.add(Dense(32, input_dim=self.state_size, activation='relu', kernel_initializer='he_uniform'))\n",
    "        model.add(Dense(32, activation='relu', kernel_initializer='he_uniform'))\n",
    "        # the output layer: output is of size num_actions\n",
    "        model.add(Dense(self.action_size, activation='relu', kernel_initializer='he_uniform'))\n",
    "        model.compile(loss='mse', optimizer=Adam(lr=self.learning_rate))\n",
    "        model.summary\n",
    "        return model\n",
    "\n",
    "    def get_action(self, state, possible_actions_index, actions):\n",
    "        \"\"\"\n",
    "        get action in a state according to an epsilon-greedy approach\n",
    "        possible_actions_index, actions are the 'ride requests' that teh driver got.\n",
    "        \"\"\"        \n",
    "        # get action from model using epsilon-greedy policy\n",
    "        # Decay in Îµ after each episode       \n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            # explore: choose a random action from the ride requests\n",
    "            return random.choice(possible_actions_index)\n",
    "        else:\n",
    "            # choose the action with the highest q(s, a)\n",
    "            # the first index corresponds to the batch size, so\n",
    "            # reshape state to (1, state_size) so that the first index corresponds to the batch size\n",
    "            state = np.array(env.state_encod_arch1(state)).reshape(1, 36)\n",
    "\n",
    "            # Use the model to predict the Q_values.\n",
    "            q_value = self.model.predict(state)\n",
    "\n",
    "            # truncate the array to only those actions that are part of the ride  requests.\n",
    "            q_vals_possible = [q_value[0][i] for i in possible_actions_index]\n",
    "\n",
    "            return possible_actions_index[np.argmax(q_vals_possible)]\n",
    "\n",
    "    def append_sample(self, state, action_index, reward, next_state, done):\n",
    "        \"\"\"appends the new agent run output to replay buffer\"\"\"\n",
    "        self.memory.append((state, action_index, reward, next_state, done))\n",
    "        \n",
    "    # pick samples randomly from replay memory (with batch_size) and train the network\n",
    "    def train_model(self):\n",
    "        \"\"\" \n",
    "        Function to train the model on eacg step run.\n",
    "        Picks the random memory events according to batch size and \n",
    "        runs it through the network to train it.\n",
    "        \"\"\"\n",
    "        if len(self.memory) > self.batch_size:\n",
    "            # Sample batch from the memory\n",
    "            mini_batch = random.sample(self.memory, self.batch_size)\n",
    "            # initialise two matrices - update_input and update_output\n",
    "            update_input = np.zeros((self.batch_size, self.state_size))\n",
    "            update_output = np.zeros((self.batch_size, self.state_size))\n",
    "            actions, rewards, done = [], [], []\n",
    "\n",
    "            # populate update_input and update_output and the lists rewards, actions, done\n",
    "            for i in range(self.batch_size):\n",
    "                state, action, reward, next_state, done_boolean = mini_batch[i]\n",
    "                update_input[i] = env.state_encod_arch1(state)     \n",
    "                actions.append(action)\n",
    "                rewards.append(reward)\n",
    "                update_output[i] = env.state_encod_arch1(next_state)\n",
    "                done.append(done_boolean)\n",
    "\n",
    "            # predict the target q-values from states s\n",
    "            target = self.model.predict(update_input)\n",
    "            # target for q-network\n",
    "            target_qval = self.model.predict(update_output)\n",
    "\n",
    "\n",
    "            # update the target values\n",
    "            for i in range(self.batch_size):\n",
    "                if done[i]:\n",
    "                    target[i][actions[i]] = rewards[i]\n",
    "                else: # non-terminal state\n",
    "                    target[i][actions[i]] = rewards[i] + self.discount_factor * np.max(target_qval[i])\n",
    "            # model fit\n",
    "            self.model.fit(update_input, target, batch_size=self.batch_size, epochs=1, verbose=0)\n",
    "            \n",
    "    def save_tracking_states(self):\n",
    "        # Use the model to predict the q_value of the state we are tacking.\n",
    "        q_value = self.model.predict(self.track_state)\n",
    "        \n",
    "        # Grab the q_value of the action index that we are tracking.\n",
    "        self.states_tracked.append(q_value[0][2])\n",
    "        \n",
    "    def save_test_states(self):\n",
    "        # Use the model to predict the q_value of the state we are tacking.\n",
    "        q_value = self.model.predict(self.track_state)\n",
    "        \n",
    "        # Grab the q_value of the action index that we are tracking.\n",
    "        self.states_test.append(q_value[0][2])\n",
    "\n",
    "    def save(self, name):\n",
    "        with open(name, 'wb') as file:  \n",
    "            pickle.dump(self.model, file,pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. DQN block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for episode in range(Episodes):\n",
    "\n",
    "    # Write code here\n",
    "    # Call the environment\n",
    "    # Call all the initialised variables of the environment\n",
    "    \n",
    "\n",
    "    #Call the DQN agent\n",
    "    \n",
    "    \n",
    "    while !terminal_state:\n",
    "        \n",
    "        # Write your code here\n",
    "        # 1. Pick epsilon-greedy action from possible actions for the current state\n",
    "        # 2. Evaluate your reward and next state\n",
    "        # 3. Append the experience to the memory\n",
    "        # 4. Train the model by calling function agent.train_model\n",
    "        # 5. Keep a track of rewards, Q-values, loss\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_time = 24*30 #30 days before which car has to be recharged\n",
    "n_episodes = 15000\n",
    "m = 5\n",
    "t = 24\n",
    "d = 7\n",
    "\n",
    "# Invoke Env class\n",
    "env = CabDriver()\n",
    "action_space, state_space, state = env.reset()\n",
    "\n",
    "# Set up state and action sizes.\n",
    "state_size = m+t+d\n",
    "action_size = len(action_space)\n",
    "\n",
    "# Invoke agent class\n",
    "agent = DQNAgent(action_size=action_size, state_size=state_size)\n",
    "\n",
    "# to store rewards in each episode\n",
    "rewards_per_episode, episodes = [], []\n",
    "# Rewards for state [0,0,0] being tracked.\n",
    "rewards_init_state = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Run the episodes, build up replay buffer and train the model.\n",
    "### Note:\n",
    "#### The moment total episode time exceeds 720 (30 days), we ignore the most recent ride and do NOT save that experience in the replay memory\n",
    "#### The init state is randomly picked from the state space for each episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "Saving Model 0\n",
      "episode 9, reward -175.0, memory_length 1383, epsilon 0.9955001547284723 total_time 725.0\n",
      "episode 19, reward 60.0, memory_length 2000, epsilon 0.9905350769930761 total_time 727.0\n",
      "episode 29, reward -139.0, memory_length 2000, epsilon 0.9855947626861951 total_time 725.0\n",
      "episode 39, reward -242.0, memory_length 2000, epsilon 0.9806790882997144 total_time 729.0\n",
      "episode 49, reward -133.0, memory_length 2000, epsilon 0.9757879309415182 total_time 726.0\n",
      "episode 59, reward -224.0, memory_length 2000, epsilon 0.9709211683324178 total_time 723.0\n",
      "episode 69, reward -296.0, memory_length 2000, epsilon 0.9660786788030947 total_time 722.0\n",
      "episode 79, reward -139.0, memory_length 2000, epsilon 0.9612603412910584 total_time 730.0\n",
      "episode 89, reward -247.0, memory_length 2000, epsilon 0.9564660353376199 total_time 722.0\n",
      "episode 99, reward 12.0, memory_length 2000, epsilon 0.9516956410848808 total_time 722.0\n",
      "episode 109, reward 162.0, memory_length 2000, epsilon 0.9469490392727365 total_time 722.0\n",
      "episode 119, reward 59.0, memory_length 2000, epsilon 0.9422261112358942 total_time 727.0\n",
      "episode 129, reward -418.0, memory_length 2000, epsilon 0.9375267389009072 total_time 728.0\n",
      "episode 139, reward 1.0, memory_length 2000, epsilon 0.9328508047832221 total_time 725.0\n",
      "episode 149, reward 49.0, memory_length 2000, epsilon 0.9281981919842428 total_time 721.0\n",
      "episode 159, reward -284.0, memory_length 2000, epsilon 0.9235687841884068 total_time 722.0\n",
      "episode 169, reward 423.0, memory_length 2000, epsilon 0.918962465660278 total_time 725.0\n",
      "episode 179, reward 24.0, memory_length 2000, epsilon 0.9143791212416534 total_time 726.0\n",
      "episode 189, reward 135.0, memory_length 2000, epsilon 0.9098186363486838 total_time 726.0\n",
      "episode 199, reward -49.0, memory_length 2000, epsilon 0.9052808969690094 total_time 728.0\n",
      "episode 209, reward 99.0, memory_length 2000, epsilon 0.9007657896589091 total_time 728.0\n",
      "episode 219, reward 54.0, memory_length 2000, epsilon 0.8962732015404654 total_time 722.0\n",
      "episode 229, reward 217.0, memory_length 2000, epsilon 0.891803020298741 total_time 725.0\n",
      "episode 239, reward 234.0, memory_length 2000, epsilon 0.8873551341789723 total_time 722.0\n",
      "episode 249, reward -260.0, memory_length 2000, epsilon 0.8829294319837746 total_time 721.0\n",
      "episode 259, reward 78.0, memory_length 2000, epsilon 0.8785258030703623 total_time 726.0\n",
      "episode 269, reward -286.0, memory_length 2000, epsilon 0.8741441373477834 total_time 725.0\n",
      "episode 279, reward 19.0, memory_length 2000, epsilon 0.8697843252741666 total_time 721.0\n",
      "episode 289, reward 83.0, memory_length 2000, epsilon 0.8654462578539829 total_time 725.0\n",
      "episode 299, reward -67.0, memory_length 2000, epsilon 0.8611298266353209 total_time 728.0\n",
      "episode 309, reward 10.0, memory_length 2000, epsilon 0.8568349237071754 total_time 725.0\n",
      "episode 319, reward 320.0, memory_length 2000, epsilon 0.8525614416967494 total_time 730.0\n",
      "episode 329, reward 127.0, memory_length 2000, epsilon 0.84830927376677 total_time 728.0\n",
      "episode 339, reward 317.0, memory_length 2000, epsilon 0.8440783136128177 total_time 722.0\n",
      "episode 349, reward 282.0, memory_length 2000, epsilon 0.8398684554606681 total_time 729.0\n",
      "episode 359, reward 90.0, memory_length 2000, epsilon 0.8356795940636483 total_time 721.0\n",
      "episode 369, reward -66.0, memory_length 2000, epsilon 0.8315116247000052 total_time 723.0\n",
      "episode 379, reward 189.0, memory_length 2000, epsilon 0.8273644431702872 total_time 728.0\n",
      "episode 389, reward 184.0, memory_length 2000, epsilon 0.8232379457947406 total_time 724.0\n",
      "episode 399, reward 244.0, memory_length 2000, epsilon 0.819132029410716 total_time 722.0\n",
      "episode 409, reward 144.0, memory_length 2000, epsilon 0.8150465913700896 total_time 727.0\n",
      "episode 419, reward 388.0, memory_length 2000, epsilon 0.8109815295366979 total_time 724.0\n",
      "episode 429, reward 63.0, memory_length 2000, epsilon 0.8069367422837833 total_time 722.0\n",
      "episode 439, reward -333.0, memory_length 2000, epsilon 0.8029121284914538 total_time 721.0\n",
      "episode 449, reward 238.0, memory_length 2000, epsilon 0.7989075875441549 total_time 726.0\n",
      "episode 459, reward 455.0, memory_length 2000, epsilon 0.7949230193281545 total_time 724.0\n",
      "episode 469, reward 122.0, memory_length 2000, epsilon 0.7909583242290396 total_time 727.0\n",
      "episode 479, reward 153.0, memory_length 2000, epsilon 0.7870134031292261 total_time 724.0\n",
      "episode 489, reward -35.0, memory_length 2000, epsilon 0.7830881574054811 total_time 725.0\n",
      "episode 499, reward 123.0, memory_length 2000, epsilon 0.7791824889264571 total_time 722.0\n",
      "episode 509, reward 257.0, memory_length 2000, epsilon 0.7752963000502389 total_time 726.0\n",
      "episode 519, reward 532.0, memory_length 2000, epsilon 0.7714294936219019 total_time 726.0\n",
      "episode 529, reward 29.0, memory_length 2000, epsilon 0.7675819729710842 total_time 721.0\n",
      "episode 539, reward -102.0, memory_length 2000, epsilon 0.763753641909569 total_time 723.0\n",
      "episode 549, reward 239.0, memory_length 2000, epsilon 0.7599444047288803 total_time 722.0\n",
      "episode 559, reward -25.0, memory_length 2000, epsilon 0.7561541661978903 total_time 726.0\n",
      "episode 569, reward 222.0, memory_length 2000, epsilon 0.7523828315604384 total_time 722.0\n",
      "episode 579, reward 180.0, memory_length 2000, epsilon 0.7486303065329623 total_time 731.0\n",
      "episode 589, reward 365.0, memory_length 2000, epsilon 0.7448964973021404 total_time 722.0\n",
      "episode 599, reward 185.0, memory_length 2000, epsilon 0.7411813105225479 total_time 721.0\n",
      "episode 609, reward 293.0, memory_length 2000, epsilon 0.7374846533143217 total_time 726.0\n",
      "episode 619, reward 321.0, memory_length 2000, epsilon 0.733806433260839 total_time 724.0\n",
      "episode 629, reward 123.0, memory_length 2000, epsilon 0.7301465584064071 total_time 723.0\n",
      "episode 639, reward 35.0, memory_length 2000, epsilon 0.7265049372539636 total_time 721.0\n",
      "episode 649, reward 537.0, memory_length 2000, epsilon 0.7228814787627905 total_time 728.0\n",
      "episode 659, reward 455.0, memory_length 2000, epsilon 0.7192760923462365 total_time 723.0\n",
      "episode 669, reward 36.0, memory_length 2000, epsilon 0.7156886878694535 total_time 726.0\n",
      "episode 679, reward -238.0, memory_length 2000, epsilon 0.7121191756471427 total_time 723.0\n",
      "episode 689, reward 302.0, memory_length 2000, epsilon 0.7085674664413126 total_time 723.0\n",
      "episode 699, reward 239.0, memory_length 2000, epsilon 0.7050334714590482 total_time 725.0\n",
      "episode 709, reward 74.0, memory_length 2000, epsilon 0.7015171023502909 total_time 721.0\n",
      "episode 719, reward 576.0, memory_length 2000, epsilon 0.6980182712056295 total_time 723.0\n",
      "episode 729, reward 108.0, memory_length 2000, epsilon 0.6945368905541035 total_time 724.0\n",
      "episode 739, reward 328.0, memory_length 2000, epsilon 0.6910728733610152 total_time 723.0\n",
      "episode 749, reward 167.0, memory_length 2000, epsilon 0.6876261330257543 total_time 724.0\n",
      "episode 759, reward 491.0, memory_length 2000, epsilon 0.684196583379633 total_time 721.0\n",
      "episode 769, reward 456.0, memory_length 2000, epsilon 0.6807841386837313 total_time 723.0\n",
      "episode 779, reward 470.0, memory_length 2000, epsilon 0.6773887136267543 total_time 723.0\n",
      "episode 789, reward 160.0, memory_length 2000, epsilon 0.6740102233228988 total_time 722.0\n",
      "episode 799, reward 246.0, memory_length 2000, epsilon 0.670648583309731 total_time 725.0\n",
      "episode 809, reward 399.0, memory_length 2000, epsilon 0.6673037095460755 total_time 722.0\n",
      "episode 819, reward 581.0, memory_length 2000, epsilon 0.6639755184099142 total_time 721.0\n",
      "episode 829, reward 335.0, memory_length 2000, epsilon 0.6606639266962953 total_time 722.0\n",
      "episode 839, reward 385.0, memory_length 2000, epsilon 0.6573688516152534 total_time 724.0\n",
      "episode 849, reward 477.0, memory_length 2000, epsilon 0.6540902107897397 total_time 722.0\n",
      "episode 859, reward 630.0, memory_length 2000, epsilon 0.6508279222535631 total_time 723.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 869, reward 640.0, memory_length 2000, epsilon 0.64758190444934 total_time 726.0\n",
      "episode 879, reward 487.0, memory_length 2000, epsilon 0.6443520762264566 total_time 723.0\n",
      "episode 889, reward 357.0, memory_length 2000, epsilon 0.6411383568390387 total_time 724.0\n",
      "episode 899, reward 182.0, memory_length 2000, epsilon 0.6379406659439346 total_time 724.0\n",
      "episode 909, reward 630.0, memory_length 2000, epsilon 0.6347589235987051 total_time 731.0\n",
      "episode 919, reward 725.0, memory_length 2000, epsilon 0.631593050259626 total_time 727.0\n",
      "episode 929, reward 367.0, memory_length 2000, epsilon 0.6284429667796988 total_time 721.0\n",
      "episode 939, reward 269.0, memory_length 2000, epsilon 0.6253085944066726 total_time 724.0\n",
      "episode 949, reward 276.0, memory_length 2000, epsilon 0.6221898547810748 total_time 722.0\n",
      "episode 959, reward 432.0, memory_length 2000, epsilon 0.6190866699342522 total_time 725.0\n",
      "episode 969, reward 871.0, memory_length 2000, epsilon 0.6159989622864221 total_time 723.0\n",
      "episode 979, reward 181.0, memory_length 2000, epsilon 0.6129266546447325 total_time 724.0\n",
      "episode 989, reward 571.0, memory_length 2000, epsilon 0.6098696702013323 total_time 723.0\n",
      "episode 999, reward 661.0, memory_length 2000, epsilon 0.6068279325314512 total_time 722.0\n",
      "Saving Model 1000\n",
      "episode 1009, reward 524.0, memory_length 2000, epsilon 0.6038013655914889 total_time 721.0\n",
      "episode 1019, reward 552.0, memory_length 2000, epsilon 0.6007898937171146 total_time 721.0\n",
      "episode 1029, reward 608.0, memory_length 2000, epsilon 0.5977934416213744 total_time 724.0\n",
      "episode 1039, reward 483.0, memory_length 2000, epsilon 0.5948119343928097 total_time 721.0\n",
      "episode 1049, reward 550.0, memory_length 2000, epsilon 0.5918452974935846 total_time 731.0\n",
      "episode 1059, reward 716.0, memory_length 2000, epsilon 0.5888934567576223 total_time 722.0\n",
      "episode 1069, reward 504.0, memory_length 2000, epsilon 0.5859563383887504 total_time 727.0\n",
      "episode 1079, reward 486.0, memory_length 2000, epsilon 0.5830338689588568 total_time 721.0\n",
      "episode 1089, reward 356.0, memory_length 2000, epsilon 0.5801259754060536 total_time 728.0\n",
      "episode 1099, reward 765.0, memory_length 2000, epsilon 0.5772325850328504 total_time 721.0\n",
      "episode 1109, reward 723.0, memory_length 2000, epsilon 0.5743536255043372 total_time 721.0\n",
      "episode 1119, reward 455.0, memory_length 2000, epsilon 0.5714890248463761 total_time 724.0\n",
      "episode 1129, reward 798.0, memory_length 2000, epsilon 0.5686387114438011 total_time 731.0\n",
      "episode 1139, reward 511.0, memory_length 2000, epsilon 0.5658026140386287 total_time 728.0\n",
      "episode 1149, reward 447.0, memory_length 2000, epsilon 0.5629806617282764 total_time 724.0\n",
      "episode 1159, reward 402.0, memory_length 2000, epsilon 0.5601727839637891 total_time 721.0\n",
      "episode 1169, reward 795.0, memory_length 2000, epsilon 0.5573789105480766 total_time 726.0\n",
      "episode 1179, reward 657.0, memory_length 2000, epsilon 0.5545989716341581 total_time 721.0\n",
      "episode 1189, reward 612.0, memory_length 2000, epsilon 0.5518328977234156 total_time 721.0\n",
      "episode 1199, reward 382.0, memory_length 2000, epsilon 0.5490806196638577 total_time 726.0\n",
      "episode 1209, reward 383.0, memory_length 2000, epsilon 0.5463420686483893 total_time 724.0\n",
      "episode 1219, reward 352.0, memory_length 2000, epsilon 0.5436171762130925 total_time 724.0\n",
      "episode 1229, reward 1206.0, memory_length 2000, epsilon 0.5409058742355145 total_time 731.0\n",
      "episode 1239, reward 676.0, memory_length 2000, epsilon 0.5382080949329644 total_time 724.0\n",
      "episode 1249, reward 423.0, memory_length 2000, epsilon 0.5355237708608195 total_time 721.0\n",
      "episode 1259, reward 601.0, memory_length 2000, epsilon 0.5328528349108379 total_time 727.0\n",
      "episode 1269, reward 575.0, memory_length 2000, epsilon 0.5301952203094819 total_time 725.0\n",
      "episode 1279, reward 678.0, memory_length 2000, epsilon 0.5275508606162479 total_time 722.0\n",
      "episode 1289, reward 602.0, memory_length 2000, epsilon 0.5249196897220061 total_time 722.0\n",
      "episode 1299, reward 485.0, memory_length 2000, epsilon 0.5223016418473468 total_time 723.0\n",
      "episode 1309, reward 947.0, memory_length 2000, epsilon 0.519696651540937 total_time 721.0\n",
      "episode 1319, reward 448.0, memory_length 2000, epsilon 0.5171046536778833 total_time 725.0\n",
      "episode 1329, reward 327.0, memory_length 2000, epsilon 0.514525583458104 total_time 724.0\n",
      "episode 1339, reward 555.0, memory_length 2000, epsilon 0.5119593764047093 total_time 723.0\n",
      "episode 1349, reward 27.0, memory_length 2000, epsilon 0.5094059683623896 total_time 721.0\n",
      "episode 1359, reward 644.0, memory_length 2000, epsilon 0.5068652954958104 total_time 728.0\n",
      "episode 1369, reward 610.0, memory_length 2000, epsilon 0.5043372942880178 total_time 723.0\n",
      "episode 1379, reward 817.0, memory_length 2000, epsilon 0.50182190153885 total_time 725.0\n",
      "episode 1389, reward 423.0, memory_length 2000, epsilon 0.49931905436335716 total_time 732.0\n",
      "episode 1399, reward 557.0, memory_length 2000, epsilon 0.49682869019022974 total_time 723.0\n",
      "episode 1409, reward 663.0, memory_length 2000, epsilon 0.49435074676023355 total_time 722.0\n",
      "episode 1419, reward 581.0, memory_length 2000, epsilon 0.4918851621246539 total_time 721.0\n",
      "episode 1429, reward 567.0, memory_length 2000, epsilon 0.4894318746437464 total_time 722.0\n",
      "episode 1439, reward 361.0, memory_length 2000, epsilon 0.4869908229851962 total_time 728.0\n",
      "episode 1449, reward 770.0, memory_length 2000, epsilon 0.48456194612258474 total_time 723.0\n",
      "episode 1459, reward 648.0, memory_length 2000, epsilon 0.48214518333386397 total_time 726.0\n",
      "episode 1469, reward 523.0, memory_length 2000, epsilon 0.47974047419983834 total_time 721.0\n",
      "episode 1479, reward 402.0, memory_length 2000, epsilon 0.4773477586026542 total_time 723.0\n",
      "episode 1489, reward 572.0, memory_length 2000, epsilon 0.474966976724297 total_time 724.0\n",
      "episode 1499, reward 968.0, memory_length 2000, epsilon 0.47259806904509577 total_time 724.0\n",
      "episode 1509, reward 711.0, memory_length 2000, epsilon 0.4702409763422352 total_time 722.0\n",
      "episode 1519, reward 1181.0, memory_length 2000, epsilon 0.4678956396882749 total_time 726.0\n",
      "episode 1529, reward 840.0, memory_length 2000, epsilon 0.4655620004496764 total_time 731.0\n",
      "episode 1539, reward 734.0, memory_length 2000, epsilon 0.46324000028533724 total_time 723.0\n",
      "episode 1549, reward 337.0, memory_length 2000, epsilon 0.4609295811451323 total_time 725.0\n",
      "episode 1559, reward 774.0, memory_length 2000, epsilon 0.4586306852684627 total_time 729.0\n",
      "episode 1569, reward 781.0, memory_length 2000, epsilon 0.4563432551828119 total_time 724.0\n",
      "episode 1579, reward 828.0, memory_length 2000, epsilon 0.4540672337023085 total_time 723.0\n",
      "episode 1589, reward 1077.0, memory_length 2000, epsilon 0.45180256392629703 total_time 726.0\n",
      "episode 1599, reward 1024.0, memory_length 2000, epsilon 0.4495491892379152 total_time 723.0\n",
      "episode 1609, reward 829.0, memory_length 2000, epsilon 0.4473070533026783 total_time 732.0\n",
      "episode 1619, reward 1009.0, memory_length 2000, epsilon 0.4450761000670712 total_time 727.0\n",
      "episode 1629, reward 734.0, memory_length 2000, epsilon 0.4428562737571469 total_time 725.0\n",
      "episode 1639, reward 820.0, memory_length 2000, epsilon 0.44064751887713194 total_time 721.0\n",
      "episode 1649, reward 594.0, memory_length 2000, epsilon 0.4384497802080393 total_time 721.0\n",
      "episode 1659, reward 676.0, memory_length 2000, epsilon 0.4362630028062879 total_time 725.0\n",
      "episode 1669, reward 1315.0, memory_length 2000, epsilon 0.43408713200232857 total_time 722.0\n",
      "episode 1679, reward 406.0, memory_length 2000, epsilon 0.43192211339927816 total_time 724.0\n",
      "episode 1689, reward 980.0, memory_length 2000, epsilon 0.4297678928715586 total_time 721.0\n",
      "episode 1699, reward 434.0, memory_length 2000, epsilon 0.4276244165635446 total_time 721.0\n",
      "episode 1709, reward 826.0, memory_length 2000, epsilon 0.42549163088821684 total_time 721.0\n",
      "episode 1719, reward 1131.0, memory_length 2000, epsilon 0.4233694825258223 total_time 725.0\n",
      "episode 1729, reward 1215.0, memory_length 2000, epsilon 0.4212579184225415 total_time 726.0\n",
      "episode 1739, reward 1012.0, memory_length 2000, epsilon 0.4191568857891617 total_time 728.0\n",
      "episode 1749, reward 622.0, memory_length 2000, epsilon 0.4170663320997578 total_time 724.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1759, reward 943.0, memory_length 2000, epsilon 0.4149862050903786 total_time 725.0\n",
      "episode 1769, reward 1113.0, memory_length 2000, epsilon 0.4129164527577405 total_time 727.0\n",
      "episode 1779, reward 990.0, memory_length 2000, epsilon 0.41085702335792745 total_time 722.0\n",
      "episode 1789, reward 672.0, memory_length 2000, epsilon 0.40880786540509717 total_time 727.0\n",
      "episode 1799, reward 570.0, memory_length 2000, epsilon 0.4067689276701942 total_time 723.0\n",
      "episode 1809, reward 1027.0, memory_length 2000, epsilon 0.40474015917966877 total_time 725.0\n",
      "episode 1819, reward 924.0, memory_length 2000, epsilon 0.4027215092142031 total_time 725.0\n",
      "episode 1829, reward 918.0, memory_length 2000, epsilon 0.4007129273074429 total_time 727.0\n",
      "episode 1839, reward 901.0, memory_length 2000, epsilon 0.39871436324473586 total_time 726.0\n",
      "episode 1849, reward 951.0, memory_length 2000, epsilon 0.3967257670618763 total_time 730.0\n",
      "episode 1859, reward 918.0, memory_length 2000, epsilon 0.3947470890438561 total_time 733.0\n",
      "episode 1869, reward 682.0, memory_length 2000, epsilon 0.3927782797236218 total_time 727.0\n",
      "episode 1879, reward 946.0, memory_length 2000, epsilon 0.3908192898808378 total_time 724.0\n",
      "episode 1889, reward 753.0, memory_length 2000, epsilon 0.388870070540656 total_time 722.0\n",
      "episode 1899, reward 404.0, memory_length 2000, epsilon 0.38693057297249134 total_time 722.0\n",
      "episode 1909, reward 584.0, memory_length 2000, epsilon 0.3850007486888037 total_time 721.0\n",
      "episode 1919, reward 672.0, memory_length 2000, epsilon 0.3830805494438854 total_time 721.0\n",
      "episode 1929, reward 1002.0, memory_length 2000, epsilon 0.38116992723265536 total_time 722.0\n",
      "episode 1939, reward 1059.0, memory_length 2000, epsilon 0.3792688342894587 total_time 723.0\n",
      "episode 1949, reward 783.0, memory_length 2000, epsilon 0.3773772230868729 total_time 727.0\n",
      "episode 1959, reward 866.0, memory_length 2000, epsilon 0.37549504633451936 total_time 725.0\n",
      "episode 1969, reward 896.0, memory_length 2000, epsilon 0.37362225697788115 total_time 723.0\n",
      "episode 1979, reward 1230.0, memory_length 2000, epsilon 0.37175880819712703 total_time 722.0\n",
      "episode 1989, reward 1220.0, memory_length 2000, epsilon 0.3699046534059402 total_time 726.0\n",
      "episode 1999, reward 1059.0, memory_length 2000, epsilon 0.3680597462503545 total_time 725.0\n",
      "Saving Model 2000\n",
      "episode 2009, reward 570.0, memory_length 2000, epsilon 0.3662240406075948 total_time 725.0\n",
      "episode 2019, reward 1103.0, memory_length 2000, epsilon 0.3643974905849244 total_time 726.0\n",
      "episode 2029, reward 851.0, memory_length 2000, epsilon 0.3625800505184978 total_time 723.0\n",
      "episode 2039, reward 1087.0, memory_length 2000, epsilon 0.3607716749722184 total_time 723.0\n",
      "episode 2049, reward 1055.0, memory_length 2000, epsilon 0.3589723187366037 total_time 723.0\n",
      "episode 2059, reward 1086.0, memory_length 2000, epsilon 0.35718193682765376 total_time 723.0\n",
      "episode 2069, reward 1089.0, memory_length 2000, epsilon 0.3554004844857278 total_time 721.0\n",
      "episode 2079, reward 1045.0, memory_length 2000, epsilon 0.35362791717442443 total_time 726.0\n",
      "episode 2089, reward 774.0, memory_length 2000, epsilon 0.35186419057946866 total_time 724.0\n",
      "episode 2099, reward 1142.0, memory_length 2000, epsilon 0.3501092606076035 total_time 725.0\n",
      "episode 2109, reward 1249.0, memory_length 2000, epsilon 0.3483630833854885 total_time 728.0\n",
      "episode 2119, reward 1280.0, memory_length 2000, epsilon 0.34662561525860197 total_time 721.0\n",
      "episode 2129, reward 1225.0, memory_length 2000, epsilon 0.34489681279015044 total_time 727.0\n",
      "episode 2139, reward 1166.0, memory_length 2000, epsilon 0.34317663275998195 total_time 725.0\n",
      "episode 2149, reward 1069.0, memory_length 2000, epsilon 0.3414650321635064 total_time 725.0\n",
      "episode 2159, reward 781.0, memory_length 2000, epsilon 0.33976196821061944 total_time 722.0\n",
      "episode 2169, reward 1190.0, memory_length 2000, epsilon 0.3380673983246338 total_time 728.0\n",
      "episode 2179, reward 1271.0, memory_length 2000, epsilon 0.336381280141214 total_time 722.0\n",
      "episode 2189, reward 423.0, memory_length 2000, epsilon 0.33470357150731744 total_time 727.0\n",
      "episode 2199, reward 979.0, memory_length 2000, epsilon 0.3330342304801412 total_time 722.0\n",
      "episode 2209, reward 549.0, memory_length 2000, epsilon 0.33137321532607245 total_time 728.0\n",
      "episode 2219, reward 1017.0, memory_length 2000, epsilon 0.3297204845196459 total_time 723.0\n",
      "episode 2229, reward 1333.0, memory_length 2000, epsilon 0.32807599674250526 total_time 722.0\n",
      "episode 2239, reward 405.0, memory_length 2000, epsilon 0.32643971088237056 total_time 721.0\n",
      "episode 2249, reward 1039.0, memory_length 2000, epsilon 0.32481158603200994 total_time 721.0\n",
      "episode 2259, reward 1016.0, memory_length 2000, epsilon 0.32319158148821747 total_time 723.0\n",
      "episode 2269, reward 951.0, memory_length 2000, epsilon 0.3215796567507951 total_time 725.0\n",
      "episode 2279, reward 873.0, memory_length 2000, epsilon 0.31997577152154044 total_time 723.0\n",
      "episode 2289, reward 974.0, memory_length 2000, epsilon 0.31837988570323916 total_time 724.0\n",
      "episode 2299, reward 1197.0, memory_length 2000, epsilon 0.3167919593986629 total_time 731.0\n",
      "episode 2309, reward 1197.0, memory_length 2000, epsilon 0.3152119529095711 total_time 722.0\n",
      "episode 2319, reward 1026.0, memory_length 2000, epsilon 0.3136398267357194 total_time 729.0\n",
      "episode 2329, reward 1039.0, memory_length 2000, epsilon 0.31207554157387146 total_time 723.0\n",
      "episode 2339, reward 830.0, memory_length 2000, epsilon 0.3105190583168168 total_time 727.0\n",
      "episode 2349, reward 938.0, memory_length 2000, epsilon 0.30897033805239293 total_time 725.0\n",
      "episode 2359, reward 833.0, memory_length 2000, epsilon 0.3074293420625127 total_time 729.0\n",
      "episode 2369, reward 1078.0, memory_length 2000, epsilon 0.3058960318221959 total_time 721.0\n",
      "episode 2379, reward 1215.0, memory_length 2000, epsilon 0.30437036899860687 total_time 723.0\n",
      "episode 2389, reward 901.0, memory_length 2000, epsilon 0.3028523154500953 total_time 722.0\n",
      "episode 2399, reward 1135.0, memory_length 2000, epsilon 0.30134183322524366 total_time 734.0\n",
      "episode 2409, reward 1323.0, memory_length 2000, epsilon 0.29983888456191743 total_time 726.0\n",
      "episode 2419, reward 634.0, memory_length 2000, epsilon 0.29834343188632195 total_time 722.0\n",
      "episode 2429, reward 983.0, memory_length 2000, epsilon 0.2968554378120623 total_time 722.0\n",
      "episode 2439, reward 1018.0, memory_length 2000, epsilon 0.2953748651392093 total_time 725.0\n",
      "episode 2449, reward 1163.0, memory_length 2000, epsilon 0.2939016768533689 total_time 724.0\n",
      "episode 2459, reward 1095.0, memory_length 2000, epsilon 0.2924358361247571 total_time 724.0\n",
      "episode 2469, reward 870.0, memory_length 2000, epsilon 0.2909773063072796 total_time 727.0\n",
      "episode 2479, reward 1141.0, memory_length 2000, epsilon 0.28952605093761474 total_time 729.0\n",
      "episode 2489, reward 685.0, memory_length 2000, epsilon 0.28808203373430286 total_time 723.0\n",
      "episode 2499, reward 1054.0, memory_length 2000, epsilon 0.28664521859683867 total_time 723.0\n",
      "episode 2509, reward 818.0, memory_length 2000, epsilon 0.2852155696047688 total_time 724.0\n",
      "episode 2519, reward 1658.0, memory_length 2000, epsilon 0.28379305101679403 total_time 722.0\n",
      "episode 2529, reward 846.0, memory_length 2000, epsilon 0.28237762726987564 total_time 725.0\n",
      "episode 2539, reward 1350.0, memory_length 2000, epsilon 0.28096926297834607 total_time 723.0\n",
      "episode 2549, reward 1307.0, memory_length 2000, epsilon 0.2795679229330249 total_time 725.0\n",
      "episode 2559, reward 938.0, memory_length 2000, epsilon 0.27817357210033783 total_time 725.0\n",
      "episode 2569, reward 1224.0, memory_length 2000, epsilon 0.27678617562144153 total_time 721.0\n",
      "episode 2579, reward 1393.0, memory_length 2000, epsilon 0.2754056988113517 total_time 722.0\n",
      "episode 2589, reward 1090.0, memory_length 2000, epsilon 0.27403210715807624 total_time 725.0\n",
      "episode 2599, reward 950.0, memory_length 2000, epsilon 0.2726653663217522 total_time 721.0\n",
      "episode 2609, reward 1171.0, memory_length 2000, epsilon 0.27130544213378754 total_time 726.0\n",
      "episode 2619, reward 1234.0, memory_length 2000, epsilon 0.2699523005960067 total_time 728.0\n",
      "episode 2629, reward 1008.0, memory_length 2000, epsilon 0.26860590787980093 total_time 725.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 2639, reward 1198.0, memory_length 2000, epsilon 0.26726623032528185 total_time 726.0\n",
      "episode 2649, reward 1260.0, memory_length 2000, epsilon 0.2659332344404412 total_time 730.0\n",
      "episode 2659, reward 1356.0, memory_length 2000, epsilon 0.2646068869003122 total_time 723.0\n",
      "episode 2669, reward 710.0, memory_length 2000, epsilon 0.2632871545461373 total_time 723.0\n",
      "episode 2679, reward 843.0, memory_length 2000, epsilon 0.261974004384539 total_time 727.0\n",
      "episode 2689, reward 792.0, memory_length 2000, epsilon 0.26066740358669477 total_time 731.0\n",
      "episode 2699, reward 982.0, memory_length 2000, epsilon 0.25936731948751673 total_time 724.0\n",
      "episode 2709, reward 1275.0, memory_length 2000, epsilon 0.2580737195848345 total_time 725.0\n",
      "episode 2719, reward 1130.0, memory_length 2000, epsilon 0.25678657153858325 total_time 728.0\n",
      "episode 2729, reward 1031.0, memory_length 2000, epsilon 0.2555058431699948 total_time 721.0\n",
      "episode 2739, reward 1157.0, memory_length 2000, epsilon 0.25423150246079323 total_time 722.0\n",
      "episode 2749, reward 1378.0, memory_length 2000, epsilon 0.2529635175523944 total_time 729.0\n",
      "episode 2759, reward 974.0, memory_length 2000, epsilon 0.25170185674510953 total_time 726.0\n",
      "episode 2769, reward 918.0, memory_length 2000, epsilon 0.25044648849735274 total_time 722.0\n",
      "episode 2779, reward 1494.0, memory_length 2000, epsilon 0.2491973814248526 total_time 724.0\n",
      "episode 2789, reward 1365.0, memory_length 2000, epsilon 0.24795450429986704 total_time 721.0\n",
      "episode 2799, reward 973.0, memory_length 2000, epsilon 0.24671782605040335 total_time 738.0\n",
      "episode 2809, reward 1643.0, memory_length 2000, epsilon 0.24548731575944074 total_time 725.0\n",
      "episode 2819, reward 932.0, memory_length 2000, epsilon 0.244262942664158 total_time 722.0\n",
      "episode 2829, reward 1532.0, memory_length 2000, epsilon 0.24304467615516384 total_time 730.0\n",
      "episode 2839, reward 1278.0, memory_length 2000, epsilon 0.24183248577573216 total_time 722.0\n",
      "episode 2849, reward 973.0, memory_length 2000, epsilon 0.24062634122104032 total_time 722.0\n",
      "episode 2859, reward 1124.0, memory_length 2000, epsilon 0.2394262123374117 total_time 722.0\n",
      "episode 2869, reward 1204.0, memory_length 2000, epsilon 0.23823206912156156 total_time 721.0\n",
      "episode 2879, reward 1383.0, memory_length 2000, epsilon 0.23704388171984747 total_time 725.0\n",
      "episode 2889, reward 1360.0, memory_length 2000, epsilon 0.23586162042752232 total_time 725.0\n",
      "episode 2899, reward 1567.0, memory_length 2000, epsilon 0.23468525568799242 total_time 732.0\n",
      "episode 2909, reward 1493.0, memory_length 2000, epsilon 0.23351475809207786 total_time 722.0\n",
      "episode 2919, reward 1391.0, memory_length 2000, epsilon 0.2323500983772779 total_time 730.0\n",
      "episode 2929, reward 1206.0, memory_length 2000, epsilon 0.2311912474270389 total_time 721.0\n",
      "episode 2939, reward 1014.0, memory_length 2000, epsilon 0.23003817627002682 total_time 723.0\n",
      "episode 2949, reward 748.0, memory_length 2000, epsilon 0.22889085607940265 total_time 727.0\n",
      "episode 2959, reward 1074.0, memory_length 2000, epsilon 0.22774925817210187 total_time 723.0\n",
      "episode 2969, reward 1595.0, memory_length 2000, epsilon 0.22661335400811736 total_time 723.0\n",
      "episode 2979, reward 1215.0, memory_length 2000, epsilon 0.2254831151897858 total_time 727.0\n",
      "episode 2989, reward 1313.0, memory_length 2000, epsilon 0.22435851346107796 total_time 721.0\n",
      "episode 2999, reward 1023.0, memory_length 2000, epsilon 0.22323952070689196 total_time 723.0\n",
      "Saving Model 3000\n",
      "episode 3009, reward 842.0, memory_length 2000, epsilon 0.22212610895235071 total_time 727.0\n",
      "episode 3019, reward 1073.0, memory_length 2000, epsilon 0.22101825036210232 total_time 729.0\n",
      "episode 3029, reward 1608.0, memory_length 2000, epsilon 0.21991591723962442 total_time 722.0\n",
      "episode 3039, reward 1301.0, memory_length 2000, epsilon 0.21881908202653141 total_time 721.0\n",
      "episode 3049, reward 1107.0, memory_length 2000, epsilon 0.21772771730188595 total_time 721.0\n",
      "episode 3059, reward 1384.0, memory_length 2000, epsilon 0.216641795781513 total_time 721.0\n",
      "episode 3069, reward 1404.0, memory_length 2000, epsilon 0.21556129031731802 total_time 729.0\n",
      "episode 3079, reward 1220.0, memory_length 2000, epsilon 0.21448617389660815 total_time 725.0\n",
      "episode 3089, reward 1188.0, memory_length 2000, epsilon 0.21341641964141686 total_time 725.0\n",
      "episode 3099, reward 1382.0, memory_length 2000, epsilon 0.21235200080783204 total_time 725.0\n",
      "episode 3109, reward 1478.0, memory_length 2000, epsilon 0.21129289078532745 total_time 724.0\n",
      "episode 3119, reward 1053.0, memory_length 2000, epsilon 0.2102390630960973 total_time 721.0\n",
      "episode 3129, reward 1699.0, memory_length 2000, epsilon 0.20919049139439458 total_time 721.0\n",
      "episode 3139, reward 1177.0, memory_length 2000, epsilon 0.20814714946587198 total_time 730.0\n",
      "episode 3149, reward 1192.0, memory_length 2000, epsilon 0.2071090112269271 total_time 723.0\n",
      "episode 3159, reward 1465.0, memory_length 2000, epsilon 0.2060760507240498 total_time 723.0\n",
      "episode 3169, reward 1488.0, memory_length 2000, epsilon 0.20504824213317377 total_time 721.0\n",
      "episode 3179, reward 1475.0, memory_length 2000, epsilon 0.2040255597590306 total_time 728.0\n",
      "episode 3189, reward 1477.0, memory_length 2000, epsilon 0.20300797803450785 total_time 727.0\n",
      "episode 3199, reward 1116.0, memory_length 2000, epsilon 0.2019954715200092 total_time 724.0\n",
      "episode 3209, reward 1040.0, memory_length 2000, epsilon 0.20098801490281926 total_time 723.0\n",
      "episode 3219, reward 1720.0, memory_length 2000, epsilon 0.19998558299646998 total_time 728.0\n",
      "episode 3229, reward 1540.0, memory_length 2000, epsilon 0.1989881507401115 total_time 724.0\n",
      "episode 3239, reward 1212.0, memory_length 2000, epsilon 0.19799569319788554 total_time 723.0\n",
      "episode 3249, reward 1227.0, memory_length 2000, epsilon 0.1970081855583018 total_time 722.0\n",
      "episode 3259, reward 1285.0, memory_length 2000, epsilon 0.19602560313361786 total_time 727.0\n",
      "episode 3269, reward 964.0, memory_length 2000, epsilon 0.19504792135922194 total_time 726.0\n",
      "episode 3279, reward 1153.0, memory_length 2000, epsilon 0.19407511579301878 total_time 726.0\n",
      "episode 3289, reward 948.0, memory_length 2000, epsilon 0.1931071621148185 total_time 724.0\n",
      "episode 3299, reward 1230.0, memory_length 2000, epsilon 0.19214403612572878 total_time 721.0\n",
      "episode 3309, reward 1211.0, memory_length 2000, epsilon 0.19118571374754967 total_time 724.0\n",
      "episode 3319, reward 1308.0, memory_length 2000, epsilon 0.1902321710221719 total_time 723.0\n",
      "episode 3329, reward 1511.0, memory_length 2000, epsilon 0.1892833841109776 total_time 721.0\n",
      "episode 3339, reward 1491.0, memory_length 2000, epsilon 0.1883393292942446 total_time 732.0\n",
      "episode 3349, reward 1185.0, memory_length 2000, epsilon 0.18739998297055327 total_time 725.0\n",
      "episode 3359, reward 1405.0, memory_length 2000, epsilon 0.18646532165619667 total_time 723.0\n",
      "episode 3369, reward 1310.0, memory_length 2000, epsilon 0.1855353219845932 total_time 725.0\n",
      "episode 3379, reward 998.0, memory_length 2000, epsilon 0.18460996070570268 total_time 721.0\n",
      "episode 3389, reward 1494.0, memory_length 2000, epsilon 0.18368921468544486 total_time 723.0\n",
      "episode 3399, reward 970.0, memory_length 2000, epsilon 0.18277306090512138 total_time 725.0\n",
      "episode 3409, reward 1386.0, memory_length 2000, epsilon 0.18186147646083992 total_time 726.0\n",
      "episode 3419, reward 1179.0, memory_length 2000, epsilon 0.18095443856294197 total_time 721.0\n",
      "episode 3429, reward 1346.0, memory_length 2000, epsilon 0.1800519245354328 total_time 721.0\n",
      "episode 3439, reward 1484.0, memory_length 2000, epsilon 0.17915391181541473 total_time 722.0\n",
      "episode 3449, reward 1490.0, memory_length 2000, epsilon 0.17826037795252297 total_time 724.0\n",
      "episode 3459, reward 1233.0, memory_length 2000, epsilon 0.17737130060836448 total_time 722.0\n",
      "episode 3469, reward 1494.0, memory_length 2000, epsilon 0.17648665755595927 total_time 726.0\n",
      "episode 3479, reward 973.0, memory_length 2000, epsilon 0.17560642667918497 total_time 724.0\n",
      "episode 3489, reward 1319.0, memory_length 2000, epsilon 0.17473058597222385 total_time 730.0\n",
      "episode 3499, reward 1401.0, memory_length 2000, epsilon 0.17385911353901257 total_time 721.0\n",
      "episode 3509, reward 1280.0, memory_length 2000, epsilon 0.17299198759269493 total_time 727.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 3519, reward 990.0, memory_length 2000, epsilon 0.1721291864550771 total_time 722.0\n",
      "episode 3529, reward 1362.0, memory_length 2000, epsilon 0.17127068855608577 total_time 723.0\n",
      "episode 3539, reward 1312.0, memory_length 2000, epsilon 0.17041647243322863 total_time 721.0\n",
      "episode 3549, reward 1028.0, memory_length 2000, epsilon 0.16956651673105824 total_time 721.0\n",
      "episode 3559, reward 1117.0, memory_length 2000, epsilon 0.16872080020063768 total_time 724.0\n",
      "episode 3569, reward 1278.0, memory_length 2000, epsilon 0.16787930169900972 total_time 723.0\n",
      "episode 3579, reward 1476.0, memory_length 2000, epsilon 0.16704200018866794 total_time 723.0\n",
      "episode 3589, reward 1224.0, memory_length 2000, epsilon 0.166208874737031 total_time 726.0\n",
      "episode 3599, reward 1053.0, memory_length 2000, epsilon 0.1653799045159192 total_time 724.0\n",
      "episode 3609, reward 1531.0, memory_length 2000, epsilon 0.16455506880103385 total_time 727.0\n",
      "episode 3619, reward 1470.0, memory_length 2000, epsilon 0.1637343469714391 total_time 723.0\n",
      "episode 3629, reward 1651.0, memory_length 2000, epsilon 0.1629177185090465 total_time 723.0\n",
      "episode 3639, reward 1702.0, memory_length 2000, epsilon 0.16210516299810185 total_time 726.0\n",
      "episode 3649, reward 1644.0, memory_length 2000, epsilon 0.16129666012467522 total_time 728.0\n",
      "episode 3659, reward 1254.0, memory_length 2000, epsilon 0.16049218967615253 total_time 722.0\n",
      "episode 3669, reward 1209.0, memory_length 2000, epsilon 0.15969173154073077 total_time 721.0\n",
      "episode 3679, reward 1249.0, memory_length 2000, epsilon 0.15889526570691476 total_time 724.0\n",
      "episode 3689, reward 1273.0, memory_length 2000, epsilon 0.15810277226301725 total_time 726.0\n",
      "episode 3699, reward 1474.0, memory_length 2000, epsilon 0.15731423139666081 total_time 723.0\n",
      "episode 3709, reward 1277.0, memory_length 2000, epsilon 0.15652962339428284 total_time 724.0\n",
      "episode 3719, reward 1283.0, memory_length 2000, epsilon 0.15574892864064224 total_time 724.0\n",
      "episode 3729, reward 1234.0, memory_length 2000, epsilon 0.1549721276183296 total_time 728.0\n",
      "episode 3739, reward 1459.0, memory_length 2000, epsilon 0.1541992009072789 total_time 725.0\n",
      "episode 3749, reward 1452.0, memory_length 2000, epsilon 0.1534301291842821 total_time 725.0\n",
      "episode 3759, reward 1280.0, memory_length 2000, epsilon 0.15266489322250604 total_time 723.0\n",
      "episode 3769, reward 1442.0, memory_length 2000, epsilon 0.15190347389101183 total_time 721.0\n",
      "episode 3779, reward 1085.0, memory_length 2000, epsilon 0.1511458521542766 total_time 721.0\n",
      "episode 3789, reward 1373.0, memory_length 2000, epsilon 0.15039200907171735 total_time 723.0\n",
      "episode 3799, reward 1418.0, memory_length 2000, epsilon 0.14964192579721786 total_time 725.0\n",
      "episode 3809, reward 1396.0, memory_length 2000, epsilon 0.14889558357865715 total_time 721.0\n",
      "episode 3819, reward 1377.0, memory_length 2000, epsilon 0.1481529637574409 total_time 730.0\n",
      "episode 3829, reward 1640.0, memory_length 2000, epsilon 0.14741404776803485 total_time 721.0\n",
      "episode 3839, reward 1656.0, memory_length 2000, epsilon 0.1466788171375009 total_time 725.0\n",
      "episode 3849, reward 1431.0, memory_length 2000, epsilon 0.14594725348503484 total_time 726.0\n",
      "episode 3859, reward 1557.0, memory_length 2000, epsilon 0.14521933852150737 total_time 728.0\n",
      "episode 3869, reward 1281.0, memory_length 2000, epsilon 0.14449505404900642 total_time 724.0\n",
      "episode 3879, reward 1611.0, memory_length 2000, epsilon 0.1437743819603825 total_time 724.0\n",
      "episode 3889, reward 1396.0, memory_length 2000, epsilon 0.14305730423879587 total_time 727.0\n",
      "episode 3899, reward 1455.0, memory_length 2000, epsilon 0.1423438029572661 total_time 725.0\n",
      "episode 3909, reward 1386.0, memory_length 2000, epsilon 0.141633860278224 total_time 721.0\n",
      "episode 3919, reward 1572.0, memory_length 2000, epsilon 0.14092745845306562 total_time 721.0\n",
      "episode 3929, reward 1368.0, memory_length 2000, epsilon 0.14022457982170855 total_time 731.0\n",
      "episode 3939, reward 1197.0, memory_length 2000, epsilon 0.13952520681215042 total_time 729.0\n",
      "episode 3949, reward 1640.0, memory_length 2000, epsilon 0.1388293219400295 total_time 723.0\n",
      "episode 3959, reward 1598.0, memory_length 2000, epsilon 0.1381369078081878 total_time 723.0\n",
      "episode 3969, reward 1539.0, memory_length 2000, epsilon 0.13744794710623595 total_time 729.0\n",
      "episode 3979, reward 1532.0, memory_length 2000, epsilon 0.13676242261012048 total_time 728.0\n",
      "episode 3989, reward 1450.0, memory_length 2000, epsilon 0.13608031718169336 total_time 724.0\n",
      "episode 3999, reward 1903.0, memory_length 2000, epsilon 0.13540161376828327 total_time 721.0\n",
      "Saving Model 4000\n",
      "episode 4009, reward 945.0, memory_length 2000, epsilon 0.13472629540226955 total_time 722.0\n",
      "episode 4019, reward 1351.0, memory_length 2000, epsilon 0.1340543452006579 total_time 726.0\n",
      "episode 4029, reward 1393.0, memory_length 2000, epsilon 0.1333857463646583 total_time 722.0\n",
      "episode 4039, reward 1465.0, memory_length 2000, epsilon 0.132720482179265 total_time 721.0\n",
      "episode 4049, reward 1574.0, memory_length 2000, epsilon 0.1320585360128386 total_time 722.0\n",
      "episode 4059, reward 1409.0, memory_length 2000, epsilon 0.1313998913166907 total_time 727.0\n",
      "episode 4069, reward 1613.0, memory_length 2000, epsilon 0.1307445316246694 total_time 725.0\n",
      "episode 4079, reward 1125.0, memory_length 2000, epsilon 0.13009244055274838 total_time 725.0\n",
      "episode 4089, reward 1451.0, memory_length 2000, epsilon 0.12944360179861678 total_time 722.0\n",
      "episode 4099, reward 1275.0, memory_length 2000, epsilon 0.12879799914127205 total_time 723.0\n",
      "episode 4109, reward 1395.0, memory_length 2000, epsilon 0.12815561644061407 total_time 721.0\n",
      "episode 4119, reward 1350.0, memory_length 2000, epsilon 0.1275164376370419 total_time 721.0\n",
      "episode 4129, reward 1485.0, memory_length 2000, epsilon 0.1268804467510521 total_time 721.0\n",
      "episode 4139, reward 1113.0, memory_length 2000, epsilon 0.12624762788283944 total_time 724.0\n",
      "episode 4149, reward 1592.0, memory_length 2000, epsilon 0.1256179652118993 total_time 727.0\n",
      "episode 4159, reward 1378.0, memory_length 2000, epsilon 0.12499144299663205 total_time 729.0\n",
      "episode 4169, reward 1567.0, memory_length 2000, epsilon 0.12436804557394966 total_time 726.0\n",
      "episode 4179, reward 1342.0, memory_length 2000, epsilon 0.12374775735888416 total_time 725.0\n",
      "episode 4189, reward 1570.0, memory_length 2000, epsilon 0.12313056284419784 total_time 726.0\n",
      "episode 4199, reward 1440.0, memory_length 2000, epsilon 0.12251644659999568 total_time 736.0\n",
      "episode 4209, reward 1477.0, memory_length 2000, epsilon 0.12190539327333952 total_time 724.0\n",
      "episode 4219, reward 1035.0, memory_length 2000, epsilon 0.12129738758786451 total_time 721.0\n",
      "episode 4229, reward 1226.0, memory_length 2000, epsilon 0.12069241434339678 total_time 724.0\n",
      "episode 4239, reward 1459.0, memory_length 2000, epsilon 0.12009045841557368 total_time 725.0\n",
      "episode 4249, reward 1233.0, memory_length 2000, epsilon 0.1194915047554657 total_time 726.0\n",
      "episode 4259, reward 1651.0, memory_length 2000, epsilon 0.11889553838920008 total_time 721.0\n",
      "episode 4269, reward 1664.0, memory_length 2000, epsilon 0.11830254441758672 total_time 721.0\n",
      "episode 4279, reward 1062.0, memory_length 2000, epsilon 0.1177125080157454 total_time 724.0\n",
      "episode 4289, reward 1340.0, memory_length 2000, epsilon 0.11712541443273533 total_time 723.0\n",
      "episode 4299, reward 1544.0, memory_length 2000, epsilon 0.11654124899118631 total_time 729.0\n",
      "episode 4309, reward 1577.0, memory_length 2000, epsilon 0.115959997086932 total_time 721.0\n",
      "episode 4319, reward 1646.0, memory_length 2000, epsilon 0.11538164418864444 total_time 727.0\n",
      "episode 4329, reward 1467.0, memory_length 2000, epsilon 0.11480617583747106 total_time 724.0\n",
      "episode 4339, reward 1364.0, memory_length 2000, epsilon 0.11423357764667307 total_time 732.0\n",
      "episode 4349, reward 1478.0, memory_length 2000, epsilon 0.11366383530126595 total_time 725.0\n",
      "episode 4359, reward 1985.0, memory_length 2000, epsilon 0.11309693455766137 total_time 726.0\n",
      "episode 4369, reward 1774.0, memory_length 2000, epsilon 0.1125328612433112 total_time 728.0\n",
      "episode 4379, reward 1440.0, memory_length 2000, epsilon 0.11197160125635315 total_time 725.0\n",
      "episode 4389, reward 1427.0, memory_length 2000, epsilon 0.11141314056525843 total_time 724.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 4399, reward 1071.0, memory_length 2000, epsilon 0.11085746520848058 total_time 728.0\n",
      "episode 4409, reward 2042.0, memory_length 2000, epsilon 0.11030456129410682 total_time 728.0\n",
      "episode 4419, reward 1213.0, memory_length 2000, epsilon 0.10975441499951036 total_time 721.0\n",
      "episode 4429, reward 1529.0, memory_length 2000, epsilon 0.10920701257100535 total_time 722.0\n",
      "episode 4439, reward 1432.0, memory_length 2000, epsilon 0.10866234032350246 total_time 724.0\n",
      "episode 4449, reward 1521.0, memory_length 2000, epsilon 0.10812038464016717 total_time 726.0\n",
      "episode 4459, reward 1891.0, memory_length 2000, epsilon 0.10758113197207911 total_time 722.0\n",
      "episode 4469, reward 1762.0, memory_length 2000, epsilon 0.10704456883789358 total_time 726.0\n",
      "episode 4479, reward 1362.0, memory_length 2000, epsilon 0.10651068182350425 total_time 724.0\n",
      "episode 4489, reward 1377.0, memory_length 2000, epsilon 0.10597945758170793 total_time 728.0\n",
      "episode 4499, reward 1986.0, memory_length 2000, epsilon 0.10545088283187094 total_time 727.0\n",
      "episode 4509, reward 1598.0, memory_length 2000, epsilon 0.10492494435959693 total_time 723.0\n",
      "episode 4519, reward 1558.0, memory_length 2000, epsilon 0.1044016290163968 total_time 724.0\n",
      "episode 4529, reward 1791.0, memory_length 2000, epsilon 0.10388092371935967 total_time 725.0\n",
      "episode 4539, reward 1436.0, memory_length 2000, epsilon 0.103362815450826 total_time 722.0\n",
      "episode 4549, reward 1603.0, memory_length 2000, epsilon 0.10284729125806202 total_time 731.0\n",
      "episode 4559, reward 1657.0, memory_length 2000, epsilon 0.1023343382529362 total_time 726.0\n",
      "episode 4569, reward 1702.0, memory_length 2000, epsilon 0.10182394361159659 total_time 726.0\n",
      "episode 4579, reward 1294.0, memory_length 2000, epsilon 0.10131609457415063 total_time 723.0\n",
      "episode 4589, reward 1618.0, memory_length 2000, epsilon 0.10081077844434586 total_time 724.0\n",
      "episode 4599, reward 1269.0, memory_length 2000, epsilon 0.10030798258925279 total_time 721.0\n",
      "episode 4609, reward 1437.0, memory_length 2000, epsilon 0.09980769443894884 total_time 726.0\n",
      "episode 4619, reward 1551.0, memory_length 2000, epsilon 0.0993099014862042 total_time 725.0\n",
      "episode 4629, reward 1395.0, memory_length 2000, epsilon 0.09881459128616905 total_time 726.0\n",
      "episode 4639, reward 1302.0, memory_length 2000, epsilon 0.09832175145606269 total_time 725.0\n",
      "episode 4649, reward 1404.0, memory_length 2000, epsilon 0.09783136967486368 total_time 725.0\n",
      "episode 4659, reward 1977.0, memory_length 2000, epsilon 0.09734343368300191 total_time 723.0\n",
      "episode 4669, reward 1095.0, memory_length 2000, epsilon 0.09685793128205217 total_time 727.0\n",
      "episode 4679, reward 1432.0, memory_length 2000, epsilon 0.09637485033442919 total_time 725.0\n",
      "episode 4689, reward 1639.0, memory_length 2000, epsilon 0.0958941787630841 total_time 724.0\n",
      "episode 4699, reward 1888.0, memory_length 2000, epsilon 0.0954159045512026 total_time 721.0\n",
      "episode 4709, reward 1746.0, memory_length 2000, epsilon 0.0949400157419044 total_time 722.0\n",
      "episode 4719, reward 1594.0, memory_length 2000, epsilon 0.09446650043794459 total_time 724.0\n",
      "episode 4729, reward 1024.0, memory_length 2000, epsilon 0.09399534680141587 total_time 723.0\n",
      "episode 4739, reward 1102.0, memory_length 2000, epsilon 0.09352654305345277 total_time 723.0\n",
      "episode 4749, reward 1635.0, memory_length 2000, epsilon 0.0930600774739372 total_time 721.0\n",
      "episode 4759, reward 1589.0, memory_length 2000, epsilon 0.09259593840120531 total_time 726.0\n",
      "episode 4769, reward 1483.0, memory_length 2000, epsilon 0.0921341142317562 total_time 721.0\n",
      "episode 4779, reward 1589.0, memory_length 2000, epsilon 0.09167459341996154 total_time 724.0\n",
      "episode 4789, reward 1411.0, memory_length 2000, epsilon 0.0912173644777771 total_time 721.0\n",
      "episode 4799, reward 1521.0, memory_length 2000, epsilon 0.09076241597445547 total_time 725.0\n",
      "episode 4809, reward 1373.0, memory_length 2000, epsilon 0.09030973653626047 total_time 721.0\n",
      "episode 4819, reward 1773.0, memory_length 2000, epsilon 0.0898593148461825 total_time 724.0\n",
      "episode 4829, reward 1661.0, memory_length 2000, epsilon 0.08941113964365587 total_time 723.0\n",
      "episode 4839, reward 1427.0, memory_length 2000, epsilon 0.08896519972427712 total_time 727.0\n",
      "episode 4849, reward 1224.0, memory_length 2000, epsilon 0.08852148393952511 total_time 723.0\n",
      "episode 4859, reward 1162.0, memory_length 2000, epsilon 0.08807998119648211 total_time 729.0\n",
      "episode 4869, reward 1759.0, memory_length 2000, epsilon 0.0876406804575565 total_time 726.0\n",
      "episode 4879, reward 1580.0, memory_length 2000, epsilon 0.08720357074020693 total_time 726.0\n",
      "episode 4889, reward 1639.0, memory_length 2000, epsilon 0.08676864111666777 total_time 726.0\n",
      "episode 4899, reward 703.0, memory_length 2000, epsilon 0.0863358807136757 total_time 728.0\n",
      "episode 4909, reward 1820.0, memory_length 2000, epsilon 0.08590527871219816 total_time 721.0\n",
      "episode 4919, reward 1581.0, memory_length 2000, epsilon 0.08547682434716262 total_time 723.0\n",
      "episode 4929, reward 1528.0, memory_length 2000, epsilon 0.08505050690718771 total_time 726.0\n",
      "episode 4939, reward 1710.0, memory_length 2000, epsilon 0.08462631573431521 total_time 726.0\n",
      "episode 4949, reward 1339.0, memory_length 2000, epsilon 0.08420424022374369 total_time 721.0\n",
      "episode 4959, reward 1451.0, memory_length 2000, epsilon 0.08378426982356336 total_time 726.0\n",
      "episode 4969, reward 1612.0, memory_length 2000, epsilon 0.08336639403449243 total_time 728.0\n",
      "episode 4979, reward 1636.0, memory_length 2000, epsilon 0.08295060240961435 total_time 723.0\n",
      "episode 4989, reward 1589.0, memory_length 2000, epsilon 0.08253688455411688 total_time 724.0\n",
      "episode 4999, reward 1411.0, memory_length 2000, epsilon 0.08212523012503205 total_time 723.0\n",
      "Saving Model 5000\n",
      "episode 5009, reward 1323.0, memory_length 2000, epsilon 0.08171562883097767 total_time 721.0\n",
      "episode 5019, reward 1233.0, memory_length 2000, epsilon 0.08130807043190014 total_time 726.0\n",
      "episode 5029, reward 1469.0, memory_length 2000, epsilon 0.0809025447388182 total_time 722.0\n",
      "episode 5039, reward 1376.0, memory_length 2000, epsilon 0.08049904161356838 total_time 721.0\n",
      "episode 5049, reward 1650.0, memory_length 2000, epsilon 0.08009755096855156 total_time 722.0\n",
      "episode 5059, reward 1555.0, memory_length 2000, epsilon 0.07969806276648073 total_time 721.0\n",
      "episode 5069, reward 1718.0, memory_length 2000, epsilon 0.07930056702013001 total_time 722.0\n",
      "episode 5079, reward 1504.0, memory_length 2000, epsilon 0.07890505379208503 total_time 723.0\n",
      "episode 5089, reward 1593.0, memory_length 2000, epsilon 0.07851151319449445 total_time 729.0\n",
      "episode 5099, reward 1611.0, memory_length 2000, epsilon 0.07811993538882292 total_time 726.0\n",
      "episode 5109, reward 1810.0, memory_length 2000, epsilon 0.07773031058560487 total_time 727.0\n",
      "episode 5119, reward 1695.0, memory_length 2000, epsilon 0.07734262904419989 total_time 727.0\n",
      "episode 5129, reward 1634.0, memory_length 2000, epsilon 0.07695688107254926 total_time 726.0\n",
      "episode 5139, reward 1649.0, memory_length 2000, epsilon 0.07657305702693368 total_time 733.0\n",
      "episode 5149, reward 1396.0, memory_length 2000, epsilon 0.07619114731173192 total_time 723.0\n",
      "episode 5159, reward 1773.0, memory_length 2000, epsilon 0.07581114237918127 total_time 727.0\n",
      "episode 5169, reward 1201.0, memory_length 2000, epsilon 0.07543303272913854 total_time 730.0\n",
      "episode 5179, reward 1731.0, memory_length 2000, epsilon 0.07505680890884289 total_time 721.0\n",
      "episode 5189, reward 1743.0, memory_length 2000, epsilon 0.07468246151267918 total_time 725.0\n",
      "episode 5199, reward 1816.0, memory_length 2000, epsilon 0.074309981181943 total_time 723.0\n",
      "episode 5209, reward 1699.0, memory_length 2000, epsilon 0.07393935860460665 total_time 722.0\n",
      "episode 5219, reward 1607.0, memory_length 2000, epsilon 0.07357058451508645 total_time 728.0\n",
      "episode 5229, reward 1608.0, memory_length 2000, epsilon 0.07320364969401096 total_time 723.0\n",
      "episode 5239, reward 1819.0, memory_length 2000, epsilon 0.07283854496799048 total_time 726.0\n",
      "episode 5249, reward 1918.0, memory_length 2000, epsilon 0.0724752612093879 total_time 722.0\n",
      "episode 5259, reward 1711.0, memory_length 2000, epsilon 0.07211378933609025 total_time 727.0\n",
      "episode 5269, reward 1770.0, memory_length 2000, epsilon 0.07175412031128199 total_time 724.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 5279, reward 704.0, memory_length 2000, epsilon 0.0713962451432187 total_time 731.0\n",
      "episode 5289, reward 1717.0, memory_length 2000, epsilon 0.07104015488500255 total_time 725.0\n",
      "episode 5299, reward 1436.0, memory_length 2000, epsilon 0.07068584063435851 total_time 722.0\n",
      "episode 5309, reward 1507.0, memory_length 2000, epsilon 0.07033329353341192 total_time 721.0\n",
      "episode 5319, reward 1876.0, memory_length 2000, epsilon 0.06998250476846683 total_time 721.0\n",
      "episode 5329, reward 1700.0, memory_length 2000, epsilon 0.0696334655697859 total_time 724.0\n",
      "episode 5339, reward 1503.0, memory_length 2000, epsilon 0.06928616721137094 total_time 722.0\n",
      "episode 5349, reward 1379.0, memory_length 2000, epsilon 0.06894060101074494 total_time 724.0\n",
      "episode 5359, reward 1242.0, memory_length 2000, epsilon 0.06859675832873488 total_time 727.0\n",
      "episode 5369, reward 1760.0, memory_length 2000, epsilon 0.06825463056925578 total_time 721.0\n",
      "episode 5379, reward 1387.0, memory_length 2000, epsilon 0.06791420917909581 total_time 726.0\n",
      "episode 5389, reward 1584.0, memory_length 2000, epsilon 0.06757548564770255 total_time 723.0\n",
      "episode 5399, reward 1224.0, memory_length 2000, epsilon 0.06723845150697004 total_time 726.0\n",
      "episode 5409, reward 1519.0, memory_length 2000, epsilon 0.06690309833102723 total_time 722.0\n",
      "episode 5419, reward 1991.0, memory_length 2000, epsilon 0.06656941773602718 total_time 722.0\n",
      "episode 5429, reward 1465.0, memory_length 2000, epsilon 0.06623740137993772 total_time 721.0\n",
      "episode 5439, reward 1558.0, memory_length 2000, epsilon 0.06590704096233263 total_time 729.0\n",
      "episode 5449, reward 1764.0, memory_length 2000, epsilon 0.06557832822418427 total_time 724.0\n",
      "episode 5459, reward 1634.0, memory_length 2000, epsilon 0.06525125494765702 total_time 725.0\n",
      "episode 5469, reward 1503.0, memory_length 2000, epsilon 0.064925812955902 total_time 728.0\n",
      "episode 5479, reward 1437.0, memory_length 2000, epsilon 0.06460199411285243 total_time 725.0\n",
      "episode 5489, reward 1629.0, memory_length 2000, epsilon 0.06427979032302036 total_time 721.0\n",
      "episode 5499, reward 1287.0, memory_length 2000, epsilon 0.06395919353129426 total_time 729.0\n",
      "episode 5509, reward 1765.0, memory_length 2000, epsilon 0.06364019572273769 total_time 721.0\n",
      "episode 5519, reward 1567.0, memory_length 2000, epsilon 0.06332278892238877 total_time 733.0\n",
      "episode 5529, reward 1787.0, memory_length 2000, epsilon 0.06300696519506098 total_time 729.0\n",
      "episode 5539, reward 1454.0, memory_length 2000, epsilon 0.06269271664514467 total_time 729.0\n",
      "episode 5549, reward 1877.0, memory_length 2000, epsilon 0.06238003541640971 total_time 724.0\n",
      "episode 5559, reward 1197.0, memory_length 2000, epsilon 0.06206891369180917 total_time 723.0\n",
      "episode 5569, reward 1877.0, memory_length 2000, epsilon 0.061759343693283675 total_time 721.0\n",
      "episode 5579, reward 1893.0, memory_length 2000, epsilon 0.06145131768156714 total_time 722.0\n",
      "episode 5589, reward 1818.0, memory_length 2000, epsilon 0.061144827955993214 total_time 721.0\n",
      "episode 5599, reward 1479.0, memory_length 2000, epsilon 0.06083986685430284 total_time 729.0\n",
      "episode 5609, reward 1720.0, memory_length 2000, epsilon 0.06053642675245258 total_time 729.0\n",
      "episode 5619, reward 1341.0, memory_length 2000, epsilon 0.06023450006442407 total_time 721.0\n",
      "episode 5629, reward 1872.0, memory_length 2000, epsilon 0.059934079242034345 total_time 729.0\n",
      "episode 5639, reward 1625.0, memory_length 2000, epsilon 0.05963515677474728 total_time 724.0\n",
      "episode 5649, reward 1949.0, memory_length 2000, epsilon 0.05933772518948558 total_time 730.0\n",
      "episode 5659, reward 1418.0, memory_length 2000, epsilon 0.05904177705044413 total_time 726.0\n",
      "episode 5669, reward 1796.0, memory_length 2000, epsilon 0.05874730495890401 total_time 729.0\n",
      "episode 5679, reward 1924.0, memory_length 2000, epsilon 0.05845430155304764 total_time 725.0\n",
      "episode 5689, reward 1213.0, memory_length 2000, epsilon 0.05816275950777461 total_time 721.0\n",
      "episode 5699, reward 1787.0, memory_length 2000, epsilon 0.05787267153451857 total_time 723.0\n",
      "episode 5709, reward 1642.0, memory_length 2000, epsilon 0.05758403038106508 total_time 726.0\n",
      "episode 5719, reward 1666.0, memory_length 2000, epsilon 0.05729682883137031 total_time 724.0\n",
      "episode 5729, reward 1558.0, memory_length 2000, epsilon 0.057011059705380535 total_time 724.0\n",
      "episode 5739, reward 1678.0, memory_length 2000, epsilon 0.05672671585885272 total_time 722.0\n",
      "episode 5749, reward 1773.0, memory_length 2000, epsilon 0.05644379018317588 total_time 723.0\n",
      "episode 5759, reward 1212.0, memory_length 2000, epsilon 0.056162275605193414 total_time 724.0\n",
      "episode 5769, reward 1553.0, memory_length 2000, epsilon 0.05588216508702621 total_time 722.0\n",
      "episode 5779, reward 1459.0, memory_length 2000, epsilon 0.055603451625896715 total_time 729.0\n",
      "episode 5789, reward 2007.0, memory_length 2000, epsilon 0.05532612825395388 total_time 721.0\n",
      "episode 5799, reward 1637.0, memory_length 2000, epsilon 0.055050188038098934 total_time 721.0\n",
      "episode 5809, reward 1760.0, memory_length 2000, epsilon 0.05477562407981217 total_time 726.0\n",
      "episode 5819, reward 1497.0, memory_length 2000, epsilon 0.0545024295149803 total_time 721.0\n",
      "episode 5829, reward 1385.0, memory_length 2000, epsilon 0.054230597513724985 total_time 724.0\n",
      "episode 5839, reward 1599.0, memory_length 2000, epsilon 0.05396012128023198 total_time 721.0\n",
      "episode 5849, reward 1680.0, memory_length 2000, epsilon 0.05369099405258145 total_time 723.0\n",
      "episode 5859, reward 1601.0, memory_length 2000, epsilon 0.05342320910257864 total_time 722.0\n",
      "episode 5869, reward 1818.0, memory_length 2000, epsilon 0.05315675973558585 total_time 726.0\n",
      "episode 5879, reward 1545.0, memory_length 2000, epsilon 0.05289163929035501 total_time 722.0\n",
      "episode 5889, reward 1862.0, memory_length 2000, epsilon 0.05262784113886122 total_time 722.0\n",
      "episode 5899, reward 1163.0, memory_length 2000, epsilon 0.05236535868613695 total_time 721.0\n",
      "episode 5909, reward 1494.0, memory_length 2000, epsilon 0.0521041853701072 total_time 724.0\n",
      "episode 5919, reward 1709.0, memory_length 2000, epsilon 0.05184431466142543 total_time 725.0\n",
      "episode 5929, reward 1967.0, memory_length 2000, epsilon 0.051585740063310445 total_time 727.0\n",
      "episode 5939, reward 2042.0, memory_length 2000, epsilon 0.051328455111383814 total_time 722.0\n",
      "episode 5949, reward 1905.0, memory_length 2000, epsilon 0.05107245337350832 total_time 726.0\n",
      "episode 5959, reward 1791.0, memory_length 2000, epsilon 0.05081772844962717 total_time 721.0\n",
      "episode 5969, reward 1933.0, memory_length 2000, epsilon 0.05056427397160404 total_time 721.0\n",
      "episode 5979, reward 1298.0, memory_length 2000, epsilon 0.05031208360306376 total_time 722.0\n",
      "episode 5989, reward 1643.0, memory_length 2000, epsilon 0.050061151039233975 total_time 726.0\n",
      "episode 5999, reward 1373.0, memory_length 2000, epsilon 0.049811470006787505 total_time 721.0\n",
      "Saving Model 6000\n",
      "episode 6009, reward 1804.0, memory_length 2000, epsilon 0.04956303426368557 total_time 721.0\n",
      "episode 6019, reward 2037.0, memory_length 2000, epsilon 0.04931583759902165 total_time 725.0\n",
      "episode 6029, reward 1658.0, memory_length 2000, epsilon 0.049069873832866234 total_time 722.0\n",
      "episode 6039, reward 1752.0, memory_length 2000, epsilon 0.04882513681611236 total_time 733.0\n",
      "episode 6049, reward 1758.0, memory_length 2000, epsilon 0.04858162043032186 total_time 721.0\n",
      "episode 6059, reward 1458.0, memory_length 2000, epsilon 0.04833931858757242 total_time 729.0\n",
      "episode 6069, reward 1801.0, memory_length 2000, epsilon 0.04809822523030535 total_time 725.0\n",
      "episode 6079, reward 1116.0, memory_length 2000, epsilon 0.04785833433117416 total_time 727.0\n",
      "episode 6089, reward 1779.0, memory_length 2000, epsilon 0.04761963989289384 total_time 726.0\n",
      "episode 6099, reward 1877.0, memory_length 2000, epsilon 0.04738213594809106 total_time 725.0\n",
      "episode 6109, reward 1811.0, memory_length 2000, epsilon 0.04714581655915481 total_time 724.0\n",
      "episode 6119, reward 1453.0, memory_length 2000, epsilon 0.04691067581808805 total_time 726.0\n",
      "episode 6129, reward 1981.0, memory_length 2000, epsilon 0.04667670784635998 total_time 729.0\n",
      "episode 6139, reward 1774.0, memory_length 2000, epsilon 0.046443906794759175 total_time 727.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 6149, reward 1827.0, memory_length 2000, epsilon 0.046212266843247196 total_time 725.0\n",
      "episode 6159, reward 1899.0, memory_length 2000, epsilon 0.04598178220081319 total_time 721.0\n",
      "episode 6169, reward 1480.0, memory_length 2000, epsilon 0.04575244710532907 total_time 722.0\n",
      "episode 6179, reward 1731.0, memory_length 2000, epsilon 0.045524255823405545 total_time 723.0\n",
      "episode 6189, reward 1450.0, memory_length 2000, epsilon 0.04529720265024866 total_time 724.0\n",
      "episode 6199, reward 1766.0, memory_length 2000, epsilon 0.045071281909517265 total_time 722.0\n",
      "episode 6209, reward 1638.0, memory_length 2000, epsilon 0.04484648795318105 total_time 729.0\n",
      "episode 6219, reward 1787.0, memory_length 2000, epsilon 0.04462281516137944 total_time 724.0\n",
      "episode 6229, reward 1353.0, memory_length 2000, epsilon 0.044400257942280974 total_time 723.0\n",
      "episode 6239, reward 1702.0, memory_length 2000, epsilon 0.04417881073194358 total_time 723.0\n",
      "episode 6249, reward 2039.0, memory_length 2000, epsilon 0.04395846799417545 total_time 727.0\n",
      "episode 6259, reward 1695.0, memory_length 2000, epsilon 0.043739224220396694 total_time 723.0\n",
      "episode 6269, reward 1511.0, memory_length 2000, epsilon 0.04352107392950154 total_time 721.0\n",
      "episode 6279, reward 1694.0, memory_length 2000, epsilon 0.04330401166772134 total_time 722.0\n",
      "episode 6289, reward 1874.0, memory_length 2000, epsilon 0.04308803200848826 total_time 726.0\n",
      "episode 6299, reward 1610.0, memory_length 2000, epsilon 0.042873129552299535 total_time 724.0\n",
      "episode 6309, reward 1693.0, memory_length 2000, epsilon 0.04265929892658262 total_time 724.0\n",
      "episode 6319, reward 1726.0, memory_length 2000, epsilon 0.04244653478556071 total_time 723.0\n",
      "episode 6329, reward 1449.0, memory_length 2000, epsilon 0.042234831810119194 total_time 731.0\n",
      "episode 6339, reward 1914.0, memory_length 2000, epsilon 0.04202418470767265 total_time 727.0\n",
      "episode 6349, reward 1846.0, memory_length 2000, epsilon 0.04181458821203258 total_time 725.0\n",
      "episode 6359, reward 1620.0, memory_length 2000, epsilon 0.04160603708327565 total_time 723.0\n",
      "episode 6369, reward 1842.0, memory_length 2000, epsilon 0.041398526107612785 total_time 725.0\n",
      "episode 6379, reward 1634.0, memory_length 2000, epsilon 0.041192050097258764 total_time 722.0\n",
      "episode 6389, reward 1833.0, memory_length 2000, epsilon 0.04098660389030262 total_time 726.0\n",
      "episode 6399, reward 1089.0, memory_length 2000, epsilon 0.04078218235057845 total_time 735.0\n",
      "episode 6409, reward 1599.0, memory_length 2000, epsilon 0.04057878036753712 total_time 723.0\n",
      "episode 6419, reward 1702.0, memory_length 2000, epsilon 0.04037639285611844 total_time 726.0\n",
      "episode 6429, reward 1792.0, memory_length 2000, epsilon 0.04017501475662412 total_time 729.0\n",
      "episode 6439, reward 1557.0, memory_length 2000, epsilon 0.03997464103459117 total_time 734.0\n",
      "episode 6449, reward 1580.0, memory_length 2000, epsilon 0.039775266680666096 total_time 729.0\n",
      "episode 6459, reward 1617.0, memory_length 2000, epsilon 0.039576886710479646 total_time 728.0\n",
      "episode 6469, reward 1828.0, memory_length 2000, epsilon 0.03937949616452228 total_time 723.0\n",
      "episode 6479, reward 1971.0, memory_length 2000, epsilon 0.03918309010802005 total_time 734.0\n",
      "episode 6489, reward 2135.0, memory_length 2000, epsilon 0.03898766363081129 total_time 727.0\n",
      "episode 6499, reward 1674.0, memory_length 2000, epsilon 0.0387932118472239 total_time 725.0\n",
      "episode 6509, reward 1467.0, memory_length 2000, epsilon 0.0385997298959532 total_time 731.0\n",
      "episode 6519, reward 1535.0, memory_length 2000, epsilon 0.03840721293994029 total_time 722.0\n",
      "episode 6529, reward 1618.0, memory_length 2000, epsilon 0.03821565616625126 total_time 722.0\n",
      "episode 6539, reward 1658.0, memory_length 2000, epsilon 0.03802505478595679 total_time 725.0\n",
      "episode 6549, reward 1845.0, memory_length 2000, epsilon 0.03783540403401242 total_time 729.0\n",
      "episode 6559, reward 1673.0, memory_length 2000, epsilon 0.03764669916913952 total_time 721.0\n",
      "episode 6569, reward 1359.0, memory_length 2000, epsilon 0.037458935473706614 total_time 721.0\n",
      "episode 6579, reward 1726.0, memory_length 2000, epsilon 0.03727210825361153 total_time 721.0\n",
      "episode 6589, reward 1888.0, memory_length 2000, epsilon 0.03708621283816403 total_time 725.0\n",
      "episode 6599, reward 1418.0, memory_length 2000, epsilon 0.03690124457996908 total_time 727.0\n",
      "episode 6609, reward 1899.0, memory_length 2000, epsilon 0.036717198854810576 total_time 721.0\n",
      "episode 6619, reward 1526.0, memory_length 2000, epsilon 0.036534071061535785 total_time 721.0\n",
      "episode 6629, reward 1431.0, memory_length 2000, epsilon 0.03635185662194034 total_time 721.0\n",
      "episode 6639, reward 1677.0, memory_length 2000, epsilon 0.03617055098065379 total_time 722.0\n",
      "episode 6649, reward 1983.0, memory_length 2000, epsilon 0.03599014960502563 total_time 728.0\n",
      "episode 6659, reward 1717.0, memory_length 2000, epsilon 0.035810647985012094 total_time 726.0\n",
      "episode 6669, reward 1666.0, memory_length 2000, epsilon 0.03563204163306331 total_time 733.0\n",
      "episode 6679, reward 1922.0, memory_length 2000, epsilon 0.035454326084011195 total_time 726.0\n",
      "episode 6689, reward 1407.0, memory_length 2000, epsilon 0.03527749689495777 total_time 731.0\n",
      "episode 6699, reward 1620.0, memory_length 2000, epsilon 0.03510154964516409 total_time 722.0\n",
      "episode 6709, reward 1963.0, memory_length 2000, epsilon 0.03492647993593973 total_time 728.0\n",
      "episode 6719, reward 1415.0, memory_length 2000, epsilon 0.034752283390532865 total_time 722.0\n",
      "episode 6729, reward 1485.0, memory_length 2000, epsilon 0.03457895565402079 total_time 725.0\n",
      "episode 6739, reward 1950.0, memory_length 2000, epsilon 0.03440649239320105 total_time 725.0\n",
      "episode 6749, reward 1771.0, memory_length 2000, epsilon 0.03423488929648313 total_time 725.0\n",
      "episode 6759, reward 1919.0, memory_length 2000, epsilon 0.0340641420737807 total_time 722.0\n",
      "episode 6769, reward 1805.0, memory_length 2000, epsilon 0.0338942464564043 total_time 723.0\n",
      "episode 6779, reward 1796.0, memory_length 2000, epsilon 0.03372519819695464 total_time 728.0\n",
      "episode 6789, reward 1467.0, memory_length 2000, epsilon 0.03355699306921642 total_time 722.0\n",
      "episode 6799, reward 1483.0, memory_length 2000, epsilon 0.03338962686805266 total_time 726.0\n",
      "episode 6809, reward 1953.0, memory_length 2000, epsilon 0.033223095409299686 total_time 727.0\n",
      "episode 6819, reward 1699.0, memory_length 2000, epsilon 0.03305739452966231 total_time 721.0\n",
      "episode 6829, reward 1926.0, memory_length 2000, epsilon 0.032892520086609915 total_time 721.0\n",
      "episode 6839, reward 1629.0, memory_length 2000, epsilon 0.03272846795827282 total_time 726.0\n",
      "episode 6849, reward 1428.0, memory_length 2000, epsilon 0.0325652340433393 total_time 728.0\n",
      "episode 6859, reward 1530.0, memory_length 2000, epsilon 0.03240281426095298 total_time 722.0\n",
      "episode 6869, reward 1751.0, memory_length 2000, epsilon 0.03224120455061084 total_time 725.0\n",
      "episode 6879, reward 1689.0, memory_length 2000, epsilon 0.03208040087206167 total_time 730.0\n",
      "episode 6889, reward 1570.0, memory_length 2000, epsilon 0.03192039920520517 total_time 721.0\n",
      "episode 6899, reward 1812.0, memory_length 2000, epsilon 0.03176119554999133 total_time 724.0\n",
      "episode 6909, reward 1503.0, memory_length 2000, epsilon 0.031602785926320466 total_time 723.0\n",
      "episode 6919, reward 1602.0, memory_length 2000, epsilon 0.03144516637394371 total_time 728.0\n",
      "episode 6929, reward 1891.0, memory_length 2000, epsilon 0.03128833295236411 total_time 727.0\n",
      "episode 6939, reward 1549.0, memory_length 2000, epsilon 0.031132281740737917 total_time 728.0\n",
      "episode 6949, reward 1404.0, memory_length 2000, epsilon 0.030977008837776713 total_time 721.0\n",
      "episode 6959, reward 1790.0, memory_length 2000, epsilon 0.030822510361649826 total_time 723.0\n",
      "episode 6969, reward 1816.0, memory_length 2000, epsilon 0.030668782449887338 total_time 723.0\n",
      "episode 6979, reward 1394.0, memory_length 2000, epsilon 0.03051582125928343 total_time 721.0\n",
      "episode 6989, reward 1525.0, memory_length 2000, epsilon 0.030363622965800367 total_time 723.0\n",
      "episode 6999, reward 1521.0, memory_length 2000, epsilon 0.030212183764472877 total_time 722.0\n",
      "Saving Model 7000\n",
      "episode 7009, reward 1710.0, memory_length 2000, epsilon 0.030061499869313068 total_time 722.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 7019, reward 1955.0, memory_length 2000, epsilon 0.029911567513215692 total_time 724.0\n",
      "episode 7029, reward 1639.0, memory_length 2000, epsilon 0.029762382947864045 total_time 727.0\n",
      "episode 7039, reward 1665.0, memory_length 2000, epsilon 0.029613942443636205 total_time 725.0\n",
      "episode 7049, reward 491.0, memory_length 2000, epsilon 0.029466242289511866 total_time 724.0\n",
      "episode 7059, reward 1928.0, memory_length 2000, epsilon 0.029319278792979464 total_time 724.0\n",
      "episode 7069, reward 1677.0, memory_length 2000, epsilon 0.029173048279943936 total_time 724.0\n",
      "episode 7079, reward 1455.0, memory_length 2000, epsilon 0.029027547094634832 total_time 723.0\n",
      "episode 7089, reward 1952.0, memory_length 2000, epsilon 0.02888277159951494 total_time 721.0\n",
      "episode 7099, reward 1761.0, memory_length 2000, epsilon 0.028738718175189356 total_time 721.0\n",
      "episode 7109, reward 1592.0, memory_length 2000, epsilon 0.028595383220314963 total_time 724.0\n",
      "episode 7119, reward 1527.0, memory_length 2000, epsilon 0.02845276315151042 total_time 727.0\n",
      "episode 7129, reward 2076.0, memory_length 2000, epsilon 0.028310854403266573 total_time 722.0\n",
      "episode 7139, reward 1816.0, memory_length 2000, epsilon 0.028169653427857343 total_time 723.0\n",
      "episode 7149, reward 1614.0, memory_length 2000, epsilon 0.028029156695250978 total_time 722.0\n",
      "episode 7159, reward 1827.0, memory_length 2000, epsilon 0.027889360693021847 total_time 732.0\n",
      "episode 7169, reward 1607.0, memory_length 2000, epsilon 0.027750261926262603 total_time 721.0\n",
      "episode 7179, reward 1360.0, memory_length 2000, epsilon 0.027611856917496857 total_time 731.0\n",
      "episode 7189, reward 1556.0, memory_length 2000, epsilon 0.027474142206592167 total_time 727.0\n",
      "episode 7199, reward 1778.0, memory_length 2000, epsilon 0.027337114350673587 total_time 721.0\n",
      "episode 7209, reward 1666.0, memory_length 2000, epsilon 0.02720076992403757 total_time 722.0\n",
      "episode 7219, reward 1382.0, memory_length 2000, epsilon 0.027065105518066374 total_time 723.0\n",
      "episode 7229, reward 1557.0, memory_length 2000, epsilon 0.026930117741142772 total_time 722.0\n",
      "episode 7239, reward 1409.0, memory_length 2000, epsilon 0.026795803218565308 total_time 728.0\n",
      "episode 7249, reward 1855.0, memory_length 2000, epsilon 0.026662158592463917 total_time 722.0\n",
      "episode 7259, reward 1217.0, memory_length 2000, epsilon 0.026529180521716 total_time 721.0\n",
      "episode 7269, reward 1629.0, memory_length 2000, epsilon 0.02639686568186286 total_time 729.0\n",
      "episode 7279, reward 2107.0, memory_length 2000, epsilon 0.026265210765026602 total_time 723.0\n",
      "episode 7289, reward 1954.0, memory_length 2000, epsilon 0.02613421247982744 total_time 725.0\n",
      "episode 7299, reward 1482.0, memory_length 2000, epsilon 0.02600386755130144 total_time 727.0\n",
      "episode 7309, reward -176.0, memory_length 2000, epsilon 0.02587417272081859 total_time 721.0\n",
      "episode 7319, reward 1307.0, memory_length 2000, epsilon 0.02574512474600138 total_time 724.0\n",
      "episode 7329, reward 1364.0, memory_length 2000, epsilon 0.02561672040064371 total_time 730.0\n",
      "episode 7339, reward 1719.0, memory_length 2000, epsilon 0.025488956474630255 total_time 734.0\n",
      "episode 7349, reward 1195.0, memory_length 2000, epsilon 0.025361829773856225 total_time 723.0\n",
      "episode 7359, reward 1723.0, memory_length 2000, epsilon 0.02523533712014747 total_time 723.0\n",
      "episode 7369, reward 1792.0, memory_length 2000, epsilon 0.02510947535118106 total_time 724.0\n",
      "episode 7379, reward 1494.0, memory_length 2000, epsilon 0.024984241320406206 total_time 725.0\n",
      "episode 7389, reward 1652.0, memory_length 2000, epsilon 0.024859631896965637 total_time 727.0\n",
      "episode 7399, reward 1648.0, memory_length 2000, epsilon 0.02473564396561726 total_time 723.0\n",
      "episode 7409, reward 1661.0, memory_length 2000, epsilon 0.024612274426656346 total_time 726.0\n",
      "episode 7419, reward 1644.0, memory_length 2000, epsilon 0.02448952019583798 total_time 726.0\n",
      "episode 7429, reward 1708.0, memory_length 2000, epsilon 0.024367378204300013 total_time 726.0\n",
      "episode 7439, reward 2013.0, memory_length 2000, epsilon 0.024245845398486288 total_time 728.0\n",
      "episode 7449, reward 1557.0, memory_length 2000, epsilon 0.024124918740070334 total_time 727.0\n",
      "episode 7459, reward 1566.0, memory_length 2000, epsilon 0.024004595205879373 total_time 735.0\n",
      "episode 7469, reward 1936.0, memory_length 2000, epsilon 0.023884871787818816 total_time 722.0\n",
      "episode 7479, reward 1821.0, memory_length 2000, epsilon 0.023765745492796957 total_time 721.0\n",
      "episode 7489, reward 1885.0, memory_length 2000, epsilon 0.023647213342650217 total_time 721.0\n",
      "episode 7499, reward 1665.0, memory_length 2000, epsilon 0.023529272374068662 total_time 728.0\n",
      "episode 7509, reward 1718.0, memory_length 2000, epsilon 0.02341191963852195 total_time 722.0\n",
      "episode 7519, reward 1026.0, memory_length 2000, epsilon 0.023295152202185577 total_time 723.0\n",
      "episode 7529, reward 1907.0, memory_length 2000, epsilon 0.023178967145867545 total_time 725.0\n",
      "episode 7539, reward 1978.0, memory_length 2000, epsilon 0.02306336156493539 total_time 724.0\n",
      "episode 7549, reward 2043.0, memory_length 2000, epsilon 0.022948332569243588 total_time 722.0\n",
      "episode 7559, reward 1737.0, memory_length 2000, epsilon 0.02283387728306124 total_time 727.0\n",
      "episode 7569, reward 1701.0, memory_length 2000, epsilon 0.022719992845000238 total_time 733.0\n",
      "episode 7579, reward 1564.0, memory_length 2000, epsilon 0.022606676407943692 total_time 721.0\n",
      "episode 7589, reward 1680.0, memory_length 2000, epsilon 0.022493925138974767 total_time 727.0\n",
      "episode 7599, reward 1641.0, memory_length 2000, epsilon 0.022381736219305885 total_time 723.0\n",
      "episode 7609, reward 1967.0, memory_length 2000, epsilon 0.022270106844208205 total_time 721.0\n",
      "episode 7619, reward 1611.0, memory_length 2000, epsilon 0.02215903422294153 total_time 721.0\n",
      "episode 7629, reward 1616.0, memory_length 2000, epsilon 0.022048515578684535 total_time 726.0\n",
      "episode 7639, reward 2034.0, memory_length 2000, epsilon 0.021938548148465385 total_time 721.0\n",
      "episode 7649, reward 1603.0, memory_length 2000, epsilon 0.02182912918309257 total_time 733.0\n",
      "episode 7659, reward 1654.0, memory_length 2000, epsilon 0.021720255947086275 total_time 722.0\n",
      "episode 7669, reward 1647.0, memory_length 2000, epsilon 0.02161192571860991 total_time 721.0\n",
      "episode 7679, reward 1512.0, memory_length 2000, epsilon 0.02150413578940214 total_time 725.0\n",
      "episode 7689, reward 1528.0, memory_length 2000, epsilon 0.021396883464709117 total_time 724.0\n",
      "episode 7699, reward 1450.0, memory_length 2000, epsilon 0.02129016606321713 total_time 725.0\n",
      "episode 7709, reward 1863.0, memory_length 2000, epsilon 0.02118398091698558 total_time 725.0\n",
      "episode 7719, reward 1713.0, memory_length 2000, epsilon 0.021078325371380293 total_time 725.0\n",
      "episode 7729, reward 1583.0, memory_length 2000, epsilon 0.020973196785007125 total_time 721.0\n",
      "episode 7739, reward 1733.0, memory_length 2000, epsilon 0.020868592529645933 total_time 721.0\n",
      "episode 7749, reward 1654.0, memory_length 2000, epsilon 0.020764509990184882 total_time 723.0\n",
      "episode 7759, reward 1800.0, memory_length 2000, epsilon 0.020660946564555086 total_time 721.0\n",
      "episode 7769, reward 1580.0, memory_length 2000, epsilon 0.020557899663665488 total_time 721.0\n",
      "episode 7779, reward 1942.0, memory_length 2000, epsilon 0.02045536671133821 total_time 721.0\n",
      "episode 7789, reward 1445.0, memory_length 2000, epsilon 0.020353345144244087 total_time 721.0\n",
      "episode 7799, reward 1945.0, memory_length 2000, epsilon 0.020251832411838658 total_time 728.0\n",
      "episode 7809, reward 1524.0, memory_length 2000, epsilon 0.0201508259762983 total_time 724.0\n",
      "episode 7819, reward 1423.0, memory_length 2000, epsilon 0.020050323312456878 total_time 725.0\n",
      "episode 7829, reward 1810.0, memory_length 2000, epsilon 0.019950321907742555 total_time 724.0\n",
      "episode 7839, reward 1619.0, memory_length 2000, epsilon 0.019850819262114995 total_time 721.0\n",
      "episode 7849, reward 1520.0, memory_length 2000, epsilon 0.019751812888002897 total_time 723.0\n",
      "episode 7859, reward 982.0, memory_length 2000, epsilon 0.019653300310241737 total_time 727.0\n",
      "episode 7869, reward 1526.0, memory_length 2000, epsilon 0.019555279066011948 total_time 724.0\n",
      "episode 7879, reward 1892.0, memory_length 2000, epsilon 0.0194577467047773 total_time 723.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 7889, reward 1683.0, memory_length 2000, epsilon 0.01936070078822371 total_time 721.0\n",
      "episode 7899, reward 1788.0, memory_length 2000, epsilon 0.019264138890198193 total_time 727.0\n",
      "episode 7909, reward 1910.0, memory_length 2000, epsilon 0.019168058596648274 total_time 727.0\n",
      "episode 7919, reward 1850.0, memory_length 2000, epsilon 0.0190724575055616 total_time 730.0\n",
      "episode 7929, reward 1598.0, memory_length 2000, epsilon 0.018977333226905934 total_time 727.0\n",
      "episode 7939, reward 1797.0, memory_length 2000, epsilon 0.018882683382569338 total_time 722.0\n",
      "episode 7949, reward 1872.0, memory_length 2000, epsilon 0.018788505606300788 total_time 727.0\n",
      "episode 7959, reward 1051.0, memory_length 2000, epsilon 0.01869479754365095 total_time 721.0\n",
      "episode 7969, reward 1671.0, memory_length 2000, epsilon 0.0186015568519134 total_time 726.0\n",
      "episode 7979, reward 1409.0, memory_length 2000, epsilon 0.018508781200065983 total_time 730.0\n",
      "episode 7989, reward 1733.0, memory_length 2000, epsilon 0.018416468268712564 total_time 722.0\n",
      "episode 7999, reward 1500.0, memory_length 2000, epsilon 0.018324615750025048 total_time 728.0\n",
      "Saving Model 8000\n",
      "episode 8009, reward 1467.0, memory_length 2000, epsilon 0.018233221347685697 total_time 721.0\n",
      "episode 8019, reward 1436.0, memory_length 2000, epsilon 0.018142282776829687 total_time 722.0\n",
      "episode 8029, reward 1378.0, memory_length 2000, epsilon 0.01805179776398801 total_time 726.0\n",
      "episode 8039, reward 1954.0, memory_length 2000, epsilon 0.01796176404703063 total_time 727.0\n",
      "episode 8049, reward 1558.0, memory_length 2000, epsilon 0.017872179375109938 total_time 725.0\n",
      "episode 8059, reward 1911.0, memory_length 2000, epsilon 0.01778304150860445 total_time 722.0\n",
      "episode 8069, reward 1806.0, memory_length 2000, epsilon 0.01769434821906289 total_time 726.0\n",
      "episode 8079, reward 1311.0, memory_length 2000, epsilon 0.017606097289148394 total_time 722.0\n",
      "episode 8089, reward 1426.0, memory_length 2000, epsilon 0.017518286512583105 total_time 721.0\n",
      "episode 8099, reward 1713.0, memory_length 2000, epsilon 0.01743091369409305 total_time 721.0\n",
      "episode 8109, reward 1815.0, memory_length 2000, epsilon 0.017343976649353204 total_time 723.0\n",
      "episode 8119, reward 1872.0, memory_length 2000, epsilon 0.017257473204932924 total_time 722.0\n",
      "episode 8129, reward 1333.0, memory_length 2000, epsilon 0.017171401198241596 total_time 722.0\n",
      "episode 8139, reward 1824.0, memory_length 2000, epsilon 0.017085758477474566 total_time 726.0\n",
      "episode 8149, reward 1756.0, memory_length 2000, epsilon 0.017000542901559345 total_time 726.0\n",
      "episode 8159, reward 1764.0, memory_length 2000, epsilon 0.016915752340102123 total_time 721.0\n",
      "episode 8169, reward 1751.0, memory_length 2000, epsilon 0.01683138467333443 total_time 726.0\n",
      "episode 8179, reward 1859.0, memory_length 2000, epsilon 0.016747437792060213 total_time 728.0\n",
      "episode 8189, reward 1824.0, memory_length 2000, epsilon 0.01666390959760305 total_time 721.0\n",
      "episode 8199, reward 1175.0, memory_length 2000, epsilon 0.016580798001753747 total_time 724.0\n",
      "episode 8209, reward 1663.0, memory_length 2000, epsilon 0.016498100926718072 total_time 726.0\n",
      "episode 8219, reward 1521.0, memory_length 2000, epsilon 0.016415816305064838 total_time 727.0\n",
      "episode 8229, reward 1723.0, memory_length 2000, epsilon 0.016333942079674212 total_time 721.0\n",
      "episode 8239, reward 1675.0, memory_length 2000, epsilon 0.016252476203686316 total_time 727.0\n",
      "episode 8249, reward 1427.0, memory_length 2000, epsilon 0.016171416640449996 total_time 728.0\n",
      "episode 8259, reward 1962.0, memory_length 2000, epsilon 0.01609076136347195 total_time 725.0\n",
      "episode 8269, reward 1674.0, memory_length 2000, epsilon 0.016010508356366054 total_time 727.0\n",
      "episode 8279, reward 1990.0, memory_length 2000, epsilon 0.015930655612802946 total_time 726.0\n",
      "episode 8289, reward 1929.0, memory_length 2000, epsilon 0.01585120113645988 total_time 727.0\n",
      "episode 8299, reward 1728.0, memory_length 2000, epsilon 0.01577214294097081 total_time 731.0\n",
      "episode 8309, reward 1807.0, memory_length 2000, epsilon 0.015693479049876717 total_time 728.0\n",
      "episode 8319, reward 1853.0, memory_length 2000, epsilon 0.015615207496576253 total_time 724.0\n",
      "episode 8329, reward 1346.0, memory_length 2000, epsilon 0.015537326324276499 total_time 724.0\n",
      "episode 8339, reward 1836.0, memory_length 2000, epsilon 0.015459833585944086 total_time 726.0\n",
      "episode 8349, reward 1906.0, memory_length 2000, epsilon 0.015382727344256523 total_time 721.0\n",
      "episode 8359, reward 1649.0, memory_length 2000, epsilon 0.015306005671553751 total_time 725.0\n",
      "episode 8369, reward 1692.0, memory_length 2000, epsilon 0.015229666649789956 total_time 721.0\n",
      "episode 8379, reward 1629.0, memory_length 2000, epsilon 0.015153708370485616 total_time 721.0\n",
      "episode 8389, reward 1860.0, memory_length 2000, epsilon 0.015078128934679799 total_time 727.0\n",
      "episode 8399, reward 1896.0, memory_length 2000, epsilon 0.015002926452882651 total_time 723.0\n",
      "episode 8409, reward 1753.0, memory_length 2000, epsilon 0.014928099045028245 total_time 726.0\n",
      "episode 8419, reward 910.0, memory_length 2000, epsilon 0.014853644840427468 total_time 726.0\n",
      "episode 8429, reward 1791.0, memory_length 2000, epsilon 0.014779561977721331 total_time 731.0\n",
      "episode 8439, reward 1819.0, memory_length 2000, epsilon 0.014705848604834405 total_time 726.0\n",
      "episode 8449, reward 1712.0, memory_length 2000, epsilon 0.014632502878928533 total_time 722.0\n",
      "episode 8459, reward 1688.0, memory_length 2000, epsilon 0.014559522966356741 total_time 725.0\n",
      "episode 8469, reward 1215.0, memory_length 2000, epsilon 0.014486907042617419 total_time 728.0\n",
      "episode 8479, reward 1559.0, memory_length 2000, epsilon 0.014414653292308677 total_time 721.0\n",
      "episode 8489, reward 1875.0, memory_length 2000, epsilon 0.014342759909083017 total_time 725.0\n",
      "episode 8499, reward 1438.0, memory_length 2000, epsilon 0.014271225095602106 total_time 721.0\n",
      "episode 8509, reward 1738.0, memory_length 2000, epsilon 0.014200047063491879 total_time 727.0\n",
      "episode 8519, reward 1953.0, memory_length 2000, epsilon 0.014129224033297824 total_time 724.0\n",
      "episode 8529, reward 1917.0, memory_length 2000, epsilon 0.014058754234440498 total_time 729.0\n",
      "episode 8539, reward 1832.0, memory_length 2000, epsilon 0.013988635905171262 total_time 726.0\n",
      "episode 8549, reward 1884.0, memory_length 2000, epsilon 0.013918867292528232 total_time 725.0\n",
      "episode 8559, reward 2127.0, memory_length 2000, epsilon 0.013849446652292442 total_time 721.0\n",
      "episode 8569, reward 1939.0, memory_length 2000, epsilon 0.0137803722489443 total_time 725.0\n",
      "episode 8579, reward 1755.0, memory_length 2000, epsilon 0.013711642355620108 total_time 725.0\n",
      "episode 8589, reward 2037.0, memory_length 2000, epsilon 0.013643255254068955 total_time 721.0\n",
      "episode 8599, reward 1862.0, memory_length 2000, epsilon 0.013575209234609741 total_time 722.0\n",
      "episode 8609, reward 1231.0, memory_length 2000, epsilon 0.013507502596088435 total_time 722.0\n",
      "episode 8619, reward 2054.0, memory_length 2000, epsilon 0.013440133645835548 total_time 727.0\n",
      "episode 8629, reward 1814.0, memory_length 2000, epsilon 0.013373100699623814 total_time 728.0\n",
      "episode 8639, reward 1798.0, memory_length 2000, epsilon 0.013306402081626088 total_time 726.0\n",
      "episode 8649, reward 1612.0, memory_length 2000, epsilon 0.013240036124373432 total_time 722.0\n",
      "episode 8659, reward 1725.0, memory_length 2000, epsilon 0.013174001168713484 total_time 723.0\n",
      "episode 8669, reward 1904.0, memory_length 2000, epsilon 0.013108295563768897 total_time 724.0\n",
      "episode 8679, reward 1544.0, memory_length 2000, epsilon 0.013042917666896131 total_time 726.0\n",
      "episode 8689, reward 1325.0, memory_length 2000, epsilon 0.012977865843644357 total_time 721.0\n",
      "episode 8699, reward 1735.0, memory_length 2000, epsilon 0.012913138467714604 total_time 724.0\n",
      "episode 8709, reward 1624.0, memory_length 2000, epsilon 0.012848733920919106 total_time 724.0\n",
      "episode 8719, reward 1927.0, memory_length 2000, epsilon 0.012784650593140833 total_time 726.0\n",
      "episode 8729, reward 2295.0, memory_length 2000, epsilon 0.012720886882293246 total_time 721.0\n",
      "episode 8739, reward 1981.0, memory_length 2000, epsilon 0.012657441194280276 total_time 721.0\n",
      "episode 8749, reward 1430.0, memory_length 2000, epsilon 0.012594311942956406 total_time 724.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 8759, reward 1878.0, memory_length 2000, epsilon 0.012531497550087062 total_time 726.0\n",
      "episode 8769, reward 1800.0, memory_length 2000, epsilon 0.012468996445309154 total_time 721.0\n",
      "episode 8779, reward 1382.0, memory_length 2000, epsilon 0.012406807066091805 total_time 725.0\n",
      "episode 8789, reward 1756.0, memory_length 2000, epsilon 0.012344927857697297 total_time 729.0\n",
      "episode 8799, reward 1845.0, memory_length 2000, epsilon 0.012283357273142198 total_time 730.0\n",
      "episode 8809, reward 1989.0, memory_length 2000, epsilon 0.012222093773158674 total_time 734.0\n",
      "episode 8819, reward 1500.0, memory_length 2000, epsilon 0.012161135826156058 total_time 723.0\n",
      "episode 8829, reward 1936.0, memory_length 2000, epsilon 0.01210048190818249 total_time 728.0\n",
      "episode 8839, reward 1967.0, memory_length 2000, epsilon 0.01204013050288686 total_time 722.0\n",
      "episode 8849, reward 1869.0, memory_length 2000, epsilon 0.011980080101480892 total_time 725.0\n",
      "episode 8859, reward 1713.0, memory_length 2000, epsilon 0.011920329202701425 total_time 721.0\n",
      "episode 8869, reward 1782.0, memory_length 2000, epsilon 0.011860876312772876 total_time 724.0\n",
      "episode 8879, reward 1177.0, memory_length 2000, epsilon 0.011801719945369903 total_time 723.0\n",
      "episode 8889, reward 1433.0, memory_length 2000, epsilon 0.011742858621580235 total_time 724.0\n",
      "episode 8899, reward 1513.0, memory_length 2000, epsilon 0.011684290869867704 total_time 727.0\n",
      "episode 8909, reward 1748.0, memory_length 2000, epsilon 0.011626015226035489 total_time 724.0\n",
      "episode 8919, reward 1944.0, memory_length 2000, epsilon 0.011568030233189445 total_time 724.0\n",
      "episode 8929, reward 1800.0, memory_length 2000, epsilon 0.011510334441701735 total_time 727.0\n",
      "episode 8939, reward 879.0, memory_length 2000, epsilon 0.011452926409174561 total_time 727.0\n",
      "episode 8949, reward 1490.0, memory_length 2000, epsilon 0.011395804700404126 total_time 728.0\n",
      "episode 8959, reward 954.0, memory_length 2000, epsilon 0.011338967887344734 total_time 727.0\n",
      "episode 8969, reward 1437.0, memory_length 2000, epsilon 0.011282414549073095 total_time 724.0\n",
      "episode 8979, reward 2017.0, memory_length 2000, epsilon 0.011226143271752802 total_time 722.0\n",
      "episode 8989, reward 1593.0, memory_length 2000, epsilon 0.011170152648599007 total_time 722.0\n",
      "episode 8999, reward 1676.0, memory_length 2000, epsilon 0.011114441279843205 total_time 727.0\n",
      "Saving Model 9000\n",
      "episode 9009, reward 1218.0, memory_length 2000, epsilon 0.011059007772698278 total_time 727.0\n",
      "episode 9019, reward 1899.0, memory_length 2000, epsilon 0.011003850741323658 total_time 724.0\n",
      "episode 9029, reward 1673.0, memory_length 2000, epsilon 0.01094896880679069 total_time 722.0\n",
      "episode 9039, reward 1344.0, memory_length 2000, epsilon 0.01089436059704815 total_time 723.0\n",
      "episode 9049, reward 1813.0, memory_length 2000, epsilon 0.010840024746887951 total_time 727.0\n",
      "episode 9059, reward 1293.0, memory_length 2000, epsilon 0.010785959897911 total_time 722.0\n",
      "episode 9069, reward 987.0, memory_length 2000, epsilon 0.010732164698493278 total_time 722.0\n",
      "episode 9079, reward 2062.0, memory_length 2000, epsilon 0.010678637803751981 total_time 726.0\n",
      "episode 9089, reward 2034.0, memory_length 2000, epsilon 0.010625377875511962 total_time 722.0\n",
      "episode 9099, reward 1942.0, memory_length 2000, epsilon 0.010572383582272233 total_time 721.0\n",
      "episode 9109, reward 1032.0, memory_length 2000, epsilon 0.010519653599172708 total_time 721.0\n",
      "episode 9119, reward 1976.0, memory_length 2000, epsilon 0.010467186607961062 total_time 726.0\n",
      "episode 9129, reward 1586.0, memory_length 2000, epsilon 0.01041498129695978 total_time 722.0\n",
      "episode 9139, reward 1089.0, memory_length 2000, epsilon 0.010363036361033369 total_time 721.0\n",
      "episode 9149, reward 1715.0, memory_length 2000, epsilon 0.010311350501555717 total_time 723.0\n",
      "episode 9159, reward 1619.0, memory_length 2000, epsilon 0.010259922426377662 total_time 721.0\n",
      "episode 9169, reward 1518.0, memory_length 2000, epsilon 0.01020875084979464 total_time 728.0\n",
      "episode 9179, reward 1557.0, memory_length 2000, epsilon 0.010157834492514568 total_time 724.0\n",
      "episode 9189, reward 1967.0, memory_length 2000, epsilon 0.010107172081625863 total_time 726.0\n",
      "episode 9199, reward 1652.0, memory_length 2000, epsilon 0.010056762350565615 total_time 727.0\n",
      "episode 9209, reward 1325.0, memory_length 2000, epsilon 0.010006604039087921 total_time 722.0\n",
      "episode 9219, reward 1514.0, memory_length 2000, epsilon 0.009956695893232382 total_time 732.0\n",
      "episode 9229, reward 1536.0, memory_length 2000, epsilon 0.009907036665292744 total_time 724.0\n",
      "episode 9239, reward 1870.0, memory_length 2000, epsilon 0.009857625113785738 total_time 721.0\n",
      "episode 9249, reward 2145.0, memory_length 2000, epsilon 0.009808460003419995 total_time 726.0\n",
      "episode 9259, reward 1607.0, memory_length 2000, epsilon 0.009759540105065195 total_time 724.0\n",
      "episode 9269, reward 1755.0, memory_length 2000, epsilon 0.009710864195721333 total_time 723.0\n",
      "episode 9279, reward 1806.0, memory_length 2000, epsilon 0.009662431058488137 total_time 723.0\n",
      "episode 9289, reward 1976.0, memory_length 2000, epsilon 0.009614239482534655 total_time 722.0\n",
      "episode 9299, reward 1132.0, memory_length 2000, epsilon 0.009566288263068979 total_time 725.0\n",
      "episode 9309, reward 1814.0, memory_length 2000, epsilon 0.009518576201308117 total_time 723.0\n",
      "episode 9319, reward 1935.0, memory_length 2000, epsilon 0.009471102104448055 total_time 729.0\n",
      "episode 9329, reward 1828.0, memory_length 2000, epsilon 0.009423864785633892 total_time 726.0\n",
      "episode 9339, reward 1833.0, memory_length 2000, epsilon 0.009376863063930195 total_time 726.0\n",
      "episode 9349, reward 1728.0, memory_length 2000, epsilon 0.009330095764291474 total_time 721.0\n",
      "episode 9359, reward 1643.0, memory_length 2000, epsilon 0.009283561717532807 total_time 721.0\n",
      "episode 9369, reward 1731.0, memory_length 2000, epsilon 0.009237259760300594 total_time 721.0\n",
      "episode 9379, reward 1575.0, memory_length 2000, epsilon 0.009191188735043496 total_time 724.0\n",
      "episode 9389, reward 1622.0, memory_length 2000, epsilon 0.009145347489983484 total_time 721.0\n",
      "episode 9399, reward 1658.0, memory_length 2000, epsilon 0.009099734879087034 total_time 722.0\n",
      "episode 9409, reward 1791.0, memory_length 2000, epsilon 0.009054349762036513 total_time 722.0\n",
      "episode 9419, reward 1842.0, memory_length 2000, epsilon 0.009009191004201625 total_time 721.0\n",
      "episode 9429, reward 1990.0, memory_length 2000, epsilon 0.008964257476611073 total_time 726.0\n",
      "episode 9439, reward 1629.0, memory_length 2000, epsilon 0.008919548055924322 total_time 722.0\n",
      "episode 9449, reward 1764.0, memory_length 2000, epsilon 0.00887506162440353 total_time 725.0\n",
      "episode 9459, reward 1923.0, memory_length 2000, epsilon 0.008830797069885592 total_time 726.0\n",
      "episode 9469, reward 1512.0, memory_length 2000, epsilon 0.008786753285754338 total_time 721.0\n",
      "episode 9479, reward 1394.0, memory_length 2000, epsilon 0.008742929170912865 total_time 721.0\n",
      "episode 9489, reward 1518.0, memory_length 2000, epsilon 0.008699323629756034 total_time 723.0\n",
      "episode 9499, reward 1514.0, memory_length 2000, epsilon 0.008655935572143034 total_time 721.0\n",
      "episode 9509, reward 1631.0, memory_length 2000, epsilon 0.008612763913370172 total_time 730.0\n",
      "episode 9519, reward 2129.0, memory_length 2000, epsilon 0.008569807574143724 total_time 723.0\n",
      "episode 9529, reward 1712.0, memory_length 2000, epsilon 0.008527065480552974 total_time 724.0\n",
      "episode 9539, reward 1492.0, memory_length 2000, epsilon 0.008484536564043358 total_time 725.0\n",
      "episode 9549, reward 1891.0, memory_length 2000, epsilon 0.008442219761389744 total_time 725.0\n",
      "episode 9559, reward 1758.0, memory_length 2000, epsilon 0.008400114014669856 total_time 723.0\n",
      "episode 9569, reward 1882.0, memory_length 2000, epsilon 0.00835821827123785 total_time 732.0\n",
      "episode 9579, reward 1814.0, memory_length 2000, epsilon 0.008316531483697952 total_time 730.0\n",
      "episode 9589, reward 1602.0, memory_length 2000, epsilon 0.008275052609878295 total_time 721.0\n",
      "episode 9599, reward 2127.0, memory_length 2000, epsilon 0.00823378061280488 total_time 725.0\n",
      "episode 9609, reward 1689.0, memory_length 2000, epsilon 0.008192714460675628 total_time 725.0\n",
      "episode 9619, reward 1674.0, memory_length 2000, epsilon 0.008151853126834597 total_time 721.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 9629, reward 1633.0, memory_length 2000, epsilon 0.00811119558974631 total_time 729.0\n",
      "episode 9639, reward 1544.0, memory_length 2000, epsilon 0.008070740832970229 total_time 722.0\n",
      "episode 9649, reward 1177.0, memory_length 2000, epsilon 0.008030487845135315 total_time 721.0\n",
      "episode 9659, reward 1206.0, memory_length 2000, epsilon 0.007990435619914792 total_time 727.0\n",
      "episode 9669, reward 1763.0, memory_length 2000, epsilon 0.007950583156000935 total_time 726.0\n",
      "episode 9679, reward 1530.0, memory_length 2000, epsilon 0.007910929457080072 total_time 722.0\n",
      "episode 9689, reward 1728.0, memory_length 2000, epsilon 0.007871473531807663 total_time 726.0\n",
      "episode 9699, reward 1725.0, memory_length 2000, epsilon 0.007832214393783524 total_time 727.0\n",
      "episode 9709, reward 1944.0, memory_length 2000, epsilon 0.007793151061527156 total_time 722.0\n",
      "episode 9719, reward 1841.0, memory_length 2000, epsilon 0.00775428255845322 total_time 727.0\n",
      "episode 9729, reward 1225.0, memory_length 2000, epsilon 0.007715607912847108 total_time 725.0\n",
      "episode 9739, reward 1656.0, memory_length 2000, epsilon 0.007677126157840679 total_time 727.0\n",
      "episode 9749, reward 1351.0, memory_length 2000, epsilon 0.007638836331388046 total_time 726.0\n",
      "episode 9759, reward 1911.0, memory_length 2000, epsilon 0.007600737476241555 total_time 725.0\n",
      "episode 9769, reward 1477.0, memory_length 2000, epsilon 0.007562828639927842 total_time 725.0\n",
      "episode 9779, reward 1864.0, memory_length 2000, epsilon 0.007525108874724024 total_time 727.0\n",
      "episode 9789, reward 1231.0, memory_length 2000, epsilon 0.0074875772376340076 total_time 726.0\n",
      "episode 9799, reward 1908.0, memory_length 2000, epsilon 0.007450232790364911 total_time 727.0\n",
      "episode 9809, reward 1634.0, memory_length 2000, epsilon 0.0074130745993036 total_time 730.0\n",
      "episode 9819, reward 1855.0, memory_length 2000, epsilon 0.007376101735493376 total_time 727.0\n",
      "episode 9829, reward 1915.0, memory_length 2000, epsilon 0.007339313274610711 total_time 722.0\n",
      "episode 9839, reward 1915.0, memory_length 2000, epsilon 0.007302708296942168 total_time 723.0\n",
      "episode 9849, reward 1693.0, memory_length 2000, epsilon 0.007266285887361399 total_time 721.0\n",
      "episode 9859, reward 2039.0, memory_length 2000, epsilon 0.007230045135306265 total_time 730.0\n",
      "episode 9869, reward 1472.0, memory_length 2000, epsilon 0.0071939851347560795 total_time 730.0\n",
      "episode 9879, reward 1315.0, memory_length 2000, epsilon 0.007158104984208951 total_time 727.0\n",
      "episode 9889, reward 1658.0, memory_length 2000, epsilon 0.007122403786659245 total_time 727.0\n",
      "episode 9899, reward 1738.0, memory_length 2000, epsilon 0.007086880649575158 total_time 728.0\n",
      "episode 9909, reward 1644.0, memory_length 2000, epsilon 0.0070515346848764255 total_time 727.0\n",
      "episode 9919, reward 1850.0, memory_length 2000, epsilon 0.007016365008912083 total_time 724.0\n",
      "episode 9929, reward 2061.0, memory_length 2000, epsilon 0.006981370742438399 total_time 727.0\n",
      "episode 9939, reward 1503.0, memory_length 2000, epsilon 0.006946551010596889 total_time 727.0\n",
      "episode 9949, reward 1312.0, memory_length 2000, epsilon 0.006911904942892444 total_time 723.0\n",
      "episode 9959, reward 1607.0, memory_length 2000, epsilon 0.006877431673171567 total_time 728.0\n",
      "episode 9969, reward 1612.0, memory_length 2000, epsilon 0.006843130339600718 total_time 727.0\n",
      "episode 9979, reward 1359.0, memory_length 2000, epsilon 0.006809000084644768 total_time 726.0\n",
      "episode 9989, reward 1810.0, memory_length 2000, epsilon 0.006775040055045574 total_time 725.0\n",
      "episode 9999, reward 1521.0, memory_length 2000, epsilon 0.006741249401800625 total_time 727.0\n",
      "Saving Model 10000\n",
      "episode 10009, reward 2291.0, memory_length 2000, epsilon 0.006707627280141827 total_time 728.0\n",
      "episode 10019, reward 1567.0, memory_length 2000, epsilon 0.0066741728495143884 total_time 723.0\n",
      "episode 10029, reward 2086.0, memory_length 2000, epsilon 0.006640885273555802 total_time 722.0\n",
      "episode 10039, reward 1707.0, memory_length 2000, epsilon 0.006607763720074933 total_time 727.0\n",
      "episode 10049, reward 1852.0, memory_length 2000, epsilon 0.006574807361031221 total_time 723.0\n",
      "episode 10059, reward 1672.0, memory_length 2000, epsilon 0.006542015372513967 total_time 722.0\n",
      "episode 10069, reward 1880.0, memory_length 2000, epsilon 0.0065093869347217625 total_time 721.0\n",
      "episode 10079, reward 1387.0, memory_length 2000, epsilon 0.006476921231941956 total_time 726.0\n",
      "episode 10089, reward 1816.0, memory_length 2000, epsilon 0.006444617452530289 total_time 723.0\n",
      "episode 10099, reward 1492.0, memory_length 2000, epsilon 0.006412474788890592 total_time 722.0\n",
      "episode 10109, reward 1890.0, memory_length 2000, epsilon 0.006380492437454601 total_time 724.0\n",
      "episode 10119, reward 1415.0, memory_length 2000, epsilon 0.0063486695986618635 total_time 724.0\n",
      "episode 10129, reward 1380.0, memory_length 2000, epsilon 0.006317005476939753 total_time 722.0\n",
      "episode 10139, reward 1878.0, memory_length 2000, epsilon 0.006285499280683576 total_time 724.0\n",
      "episode 10149, reward 2018.0, memory_length 2000, epsilon 0.006254150222236782 total_time 725.0\n",
      "episode 10159, reward 1756.0, memory_length 2000, epsilon 0.006222957517871287 total_time 725.0\n",
      "episode 10169, reward 1913.0, memory_length 2000, epsilon 0.00619192038776785 total_time 733.0\n",
      "episode 10179, reward 1848.0, memory_length 2000, epsilon 0.006161038055996604 total_time 725.0\n",
      "episode 10189, reward 1901.0, memory_length 2000, epsilon 0.006130309750497645 total_time 723.0\n",
      "episode 10199, reward 1835.0, memory_length 2000, epsilon 0.006099734703061736 total_time 721.0\n",
      "episode 10209, reward 1704.0, memory_length 2000, epsilon 0.0060693121493110985 total_time 721.0\n",
      "episode 10219, reward 1361.0, memory_length 2000, epsilon 0.0060390413286803045 total_time 723.0\n",
      "episode 10229, reward 1355.0, memory_length 2000, epsilon 0.006008921484397255 total_time 726.0\n",
      "episode 10239, reward 1953.0, memory_length 2000, epsilon 0.005978951863464286 total_time 721.0\n",
      "episode 10249, reward 1765.0, memory_length 2000, epsilon 0.0059491317166393085 total_time 721.0\n",
      "episode 10259, reward 1932.0, memory_length 2000, epsilon 0.005919460298417096 total_time 721.0\n",
      "episode 10269, reward 1593.0, memory_length 2000, epsilon 0.005889936867010651 total_time 723.0\n",
      "episode 10279, reward 1626.0, memory_length 2000, epsilon 0.005860560684332649 total_time 729.0\n",
      "episode 10289, reward 1603.0, memory_length 2000, epsilon 0.005831331015976992 total_time 729.0\n",
      "episode 10299, reward 1947.0, memory_length 2000, epsilon 0.005802247131200451 total_time 723.0\n",
      "episode 10309, reward 1491.0, memory_length 2000, epsilon 0.005773308302904384 total_time 729.0\n",
      "episode 10319, reward 1246.0, memory_length 2000, epsilon 0.005744513807616589 total_time 722.0\n",
      "episode 10329, reward 1711.0, memory_length 2000, epsilon 0.0057158629254731785 total_time 721.0\n",
      "episode 10339, reward 1818.0, memory_length 2000, epsilon 0.005687354940200605 total_time 725.0\n",
      "episode 10349, reward 1755.0, memory_length 2000, epsilon 0.005658989139097755 total_time 728.0\n",
      "episode 10359, reward 1855.0, memory_length 2000, epsilon 0.005630764813018121 total_time 729.0\n",
      "episode 10369, reward 1841.0, memory_length 2000, epsilon 0.005602681256352081 total_time 721.0\n",
      "episode 10379, reward 1395.0, memory_length 2000, epsilon 0.005574737767009257 total_time 727.0\n",
      "episode 10389, reward 1986.0, memory_length 2000, epsilon 0.005546933646400958 total_time 721.0\n",
      "episode 10399, reward 1621.0, memory_length 2000, epsilon 0.00551926819942272 total_time 726.0\n",
      "episode 10409, reward 1593.0, memory_length 2000, epsilon 0.0054917407344369324 total_time 721.0\n",
      "episode 10419, reward 1331.0, memory_length 2000, epsilon 0.005464350563255534 total_time 721.0\n",
      "episode 10429, reward 1503.0, memory_length 2000, epsilon 0.00543709700112282 total_time 731.0\n",
      "episode 10439, reward 1459.0, memory_length 2000, epsilon 0.0054099793666983155 total_time 727.0\n",
      "episode 10449, reward 1422.0, memory_length 2000, epsilon 0.00538299698203975 total_time 727.0\n",
      "episode 10459, reward 1825.0, memory_length 2000, epsilon 0.005356149172586098 total_time 722.0\n",
      "episode 10469, reward 1872.0, memory_length 2000, epsilon 0.005329435267140728 total_time 724.0\n",
      "episode 10479, reward 1630.0, memory_length 2000, epsilon 0.005302854597854607 total_time 729.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 10489, reward 1801.0, memory_length 2000, epsilon 0.005276406500209628 total_time 721.0\n",
      "episode 10499, reward 1774.0, memory_length 2000, epsilon 0.005250090313001966 total_time 725.0\n",
      "episode 10509, reward 1866.0, memory_length 2000, epsilon 0.005223905378325572 total_time 726.0\n",
      "episode 10519, reward 1245.0, memory_length 2000, epsilon 0.005197851041555715 total_time 725.0\n",
      "episode 10529, reward 1158.0, memory_length 2000, epsilon 0.005171926651332619 total_time 724.0\n",
      "episode 10539, reward 1175.0, memory_length 2000, epsilon 0.005146131559545177 total_time 721.0\n",
      "episode 10549, reward 1906.0, memory_length 2000, epsilon 0.005120465121314752 total_time 724.0\n",
      "episode 10559, reward 2133.0, memory_length 2000, epsilon 0.005094926694979046 total_time 728.0\n",
      "episode 10569, reward 1864.0, memory_length 2000, epsilon 0.00506951564207608 total_time 727.0\n",
      "episode 10579, reward 309.0, memory_length 2000, epsilon 0.005044231327328204 total_time 726.0\n",
      "episode 10589, reward 1883.0, memory_length 2000, epsilon 0.005019073118626231 total_time 725.0\n",
      "episode 10599, reward 797.0, memory_length 2000, epsilon 0.004994040387013635 total_time 724.0\n",
      "episode 10609, reward 1873.0, memory_length 2000, epsilon 0.00496913250667082 total_time 721.0\n",
      "episode 10619, reward 1247.0, memory_length 2000, epsilon 0.004944348854899481 total_time 725.0\n",
      "episode 10629, reward 1420.0, memory_length 2000, epsilon 0.004919688812107034 total_time 721.0\n",
      "episode 10639, reward 1991.0, memory_length 2000, epsilon 0.004895151761791122 total_time 728.0\n",
      "episode 10649, reward 1821.0, memory_length 2000, epsilon 0.004870737090524206 total_time 721.0\n",
      "episode 10659, reward 1589.0, memory_length 2000, epsilon 0.004846444187938244 total_time 721.0\n",
      "episode 10669, reward 1008.0, memory_length 2000, epsilon 0.0048222724467093985 total_time 726.0\n",
      "episode 10679, reward 1819.0, memory_length 2000, epsilon 0.004798221262542881 total_time 729.0\n",
      "episode 10689, reward 1689.0, memory_length 2000, epsilon 0.004774290034157834 total_time 727.0\n",
      "episode 10699, reward 1571.0, memory_length 2000, epsilon 0.0047504781632723035 total_time 727.0\n",
      "episode 10709, reward 1854.0, memory_length 2000, epsilon 0.004726785054588276 total_time 721.0\n",
      "episode 10719, reward 1625.0, memory_length 2000, epsilon 0.004703210115776799 total_time 724.0\n",
      "episode 10729, reward 1180.0, memory_length 2000, epsilon 0.004679752757463171 total_time 730.0\n",
      "episode 10739, reward 1153.0, memory_length 2000, epsilon 0.004656412393212222 total_time 723.0\n",
      "episode 10749, reward 1287.0, memory_length 2000, epsilon 0.004633188439513625 total_time 729.0\n",
      "episode 10759, reward 1818.0, memory_length 2000, epsilon 0.004610080315767327 total_time 726.0\n",
      "episode 10769, reward 1842.0, memory_length 2000, epsilon 0.004587087444269032 total_time 725.0\n",
      "episode 10779, reward 1668.0, memory_length 2000, epsilon 0.004564209250195755 total_time 722.0\n",
      "episode 10789, reward 1829.0, memory_length 2000, epsilon 0.004541445161591452 total_time 722.0\n",
      "episode 10799, reward 1860.0, memory_length 2000, epsilon 0.004518794609352723 total_time 725.0\n",
      "episode 10809, reward 1715.0, memory_length 2000, epsilon 0.004496257027214578 total_time 723.0\n",
      "episode 10819, reward 1991.0, memory_length 2000, epsilon 0.004473831851736298 total_time 724.0\n",
      "episode 10829, reward 1668.0, memory_length 2000, epsilon 0.0044515185222873226 total_time 722.0\n",
      "episode 10839, reward 1945.0, memory_length 2000, epsilon 0.004429316481033255 total_time 731.0\n",
      "episode 10849, reward 1787.0, memory_length 2000, epsilon 0.004407225172921907 total_time 728.0\n",
      "episode 10859, reward 1605.0, memory_length 2000, epsilon 0.004385244045669425 total_time 722.0\n",
      "episode 10869, reward 1636.0, memory_length 2000, epsilon 0.004363372549746483 total_time 726.0\n",
      "episode 10879, reward 1837.0, memory_length 2000, epsilon 0.004341610138364544 total_time 732.0\n",
      "episode 10889, reward 1913.0, memory_length 2000, epsilon 0.00431995626746219 total_time 727.0\n",
      "episode 10899, reward 1859.0, memory_length 2000, epsilon 0.004298410395691517 total_time 726.0\n",
      "episode 10909, reward 1464.0, memory_length 2000, epsilon 0.004276971984404615 total_time 726.0\n",
      "episode 10919, reward 1905.0, memory_length 2000, epsilon 0.0042556404976400826 total_time 726.0\n",
      "episode 10929, reward 1638.0, memory_length 2000, epsilon 0.004234415402109639 total_time 723.0\n",
      "episode 10939, reward 2099.0, memory_length 2000, epsilon 0.004213296167184791 total_time 724.0\n",
      "episode 10949, reward 1971.0, memory_length 2000, epsilon 0.004192282264883566 total_time 721.0\n",
      "episode 10959, reward 1469.0, memory_length 2000, epsilon 0.00417137316985731 total_time 721.0\n",
      "episode 10969, reward 1572.0, memory_length 2000, epsilon 0.004150568359377561 total_time 723.0\n",
      "episode 10979, reward 1768.0, memory_length 2000, epsilon 0.004129867313322968 total_time 722.0\n",
      "episode 10989, reward 1729.0, memory_length 2000, epsilon 0.004109269514166309 total_time 722.0\n",
      "episode 10999, reward 1532.0, memory_length 2000, epsilon 0.004088774446961528 total_time 724.0\n",
      "Saving Model 11000\n",
      "episode 11009, reward 2004.0, memory_length 2000, epsilon 0.0040683815993308795 total_time 723.0\n",
      "episode 11019, reward 1762.0, memory_length 2000, epsilon 0.004048090461452108 total_time 728.0\n",
      "episode 11029, reward 1881.0, memory_length 2000, epsilon 0.004027900526045712 total_time 726.0\n",
      "episode 11039, reward 1898.0, memory_length 2000, epsilon 0.004007811288362254 total_time 726.0\n",
      "episode 11049, reward 1710.0, memory_length 2000, epsilon 0.0039878222461697446 total_time 723.0\n",
      "episode 11059, reward 1554.0, memory_length 2000, epsilon 0.003967932899741086 total_time 735.0\n",
      "episode 11069, reward 2000.0, memory_length 2000, epsilon 0.003948142751841587 total_time 722.0\n",
      "episode 11079, reward 1928.0, memory_length 2000, epsilon 0.003928451307716517 total_time 726.0\n",
      "episode 11089, reward 1285.0, memory_length 2000, epsilon 0.003908858075078747 total_time 723.0\n",
      "episode 11099, reward 2169.0, memory_length 2000, epsilon 0.0038893625640964405 total_time 729.0\n",
      "episode 11109, reward 1612.0, memory_length 2000, epsilon 0.0038699642873808076 total_time 729.0\n",
      "episode 11119, reward 1811.0, memory_length 2000, epsilon 0.0038506627599739197 total_time 726.0\n",
      "episode 11129, reward 1314.0, memory_length 2000, epsilon 0.0038314574993365868 total_time 721.0\n",
      "episode 11139, reward 1368.0, memory_length 2000, epsilon 0.0038123480253362927 total_time 728.0\n",
      "episode 11149, reward 1907.0, memory_length 2000, epsilon 0.0037933338602351885 total_time 724.0\n",
      "episode 11159, reward 1766.0, memory_length 2000, epsilon 0.003774414528678163 total_time 722.0\n",
      "episode 11169, reward 1752.0, memory_length 2000, epsilon 0.003755589557680939 total_time 724.0\n",
      "episode 11179, reward 1676.0, memory_length 2000, epsilon 0.003736858476618261 total_time 724.0\n",
      "episode 11189, reward 1739.0, memory_length 2000, epsilon 0.0037182208172121265 total_time 723.0\n",
      "episode 11199, reward 1793.0, memory_length 2000, epsilon 0.003699676113520079 total_time 729.0\n",
      "episode 11209, reward 2298.0, memory_length 2000, epsilon 0.003681223901923562 total_time 723.0\n",
      "episode 11219, reward 1641.0, memory_length 2000, epsilon 0.0036628637211163235 total_time 721.0\n",
      "episode 11229, reward 1326.0, memory_length 2000, epsilon 0.0036445951120928836 total_time 722.0\n",
      "episode 11239, reward 1829.0, memory_length 2000, epsilon 0.0036264176181370726 total_time 729.0\n",
      "episode 11249, reward 1360.0, memory_length 2000, epsilon 0.003608330784810591 total_time 724.0\n",
      "episode 11259, reward 1447.0, memory_length 2000, epsilon 0.0035903341599416634 total_time 724.0\n",
      "episode 11269, reward 1662.0, memory_length 2000, epsilon 0.0035724272936137314 total_time 725.0\n",
      "episode 11279, reward 945.0, memory_length 2000, epsilon 0.003554609738154204 total_time 721.0\n",
      "episode 11289, reward 1815.0, memory_length 2000, epsilon 0.003536881048123266 total_time 724.0\n",
      "episode 11299, reward 2090.0, memory_length 2000, epsilon 0.003519240780302744 total_time 725.0\n",
      "episode 11309, reward 1891.0, memory_length 2000, epsilon 0.00350168849368502 total_time 722.0\n",
      "episode 11319, reward 2075.0, memory_length 2000, epsilon 0.003484223749462022 total_time 725.0\n",
      "episode 11329, reward 1812.0, memory_length 2000, epsilon 0.00346684611101423 total_time 724.0\n",
      "episode 11339, reward 1620.0, memory_length 2000, epsilon 0.0034495551438997784 total_time 726.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 11349, reward 1715.0, memory_length 2000, epsilon 0.003432350415843589 total_time 723.0\n",
      "episode 11359, reward 1505.0, memory_length 2000, epsilon 0.003415231496726564 total_time 726.0\n",
      "episode 11369, reward 1784.0, memory_length 2000, epsilon 0.0033981979585748336 total_time 724.0\n",
      "episode 11379, reward 1466.0, memory_length 2000, epsilon 0.0033812493755490574 total_time 726.0\n",
      "episode 11389, reward 1872.0, memory_length 2000, epsilon 0.003364385323933774 total_time 733.0\n",
      "episode 11399, reward 1496.0, memory_length 2000, epsilon 0.0033476053821268207 total_time 726.0\n",
      "episode 11409, reward 1790.0, memory_length 2000, epsilon 0.0033309091306287742 total_time 722.0\n",
      "episode 11419, reward 2079.0, memory_length 2000, epsilon 0.0033142961520324795 total_time 721.0\n",
      "episode 11429, reward 1271.0, memory_length 2000, epsilon 0.0032977660310126045 total_time 728.0\n",
      "episode 11439, reward 1837.0, memory_length 2000, epsilon 0.0032813183543152643 total_time 721.0\n",
      "episode 11449, reward 1563.0, memory_length 2000, epsilon 0.003264952710747684 total_time 725.0\n",
      "episode 11459, reward 392.0, memory_length 2000, epsilon 0.003248668691167922 total_time 722.0\n",
      "episode 11469, reward 1494.0, memory_length 2000, epsilon 0.0032324658884746406 total_time 726.0\n",
      "episode 11479, reward 1380.0, memory_length 2000, epsilon 0.0032163438975969265 total_time 724.0\n",
      "episode 11489, reward 750.0, memory_length 2000, epsilon 0.0032003023154841726 total_time 722.0\n",
      "episode 11499, reward 1685.0, memory_length 2000, epsilon 0.0031843407410959887 total_time 721.0\n",
      "episode 11509, reward 2108.0, memory_length 2000, epsilon 0.0031684587753921835 total_time 725.0\n",
      "episode 11519, reward 1622.0, memory_length 2000, epsilon 0.003152656021322787 total_time 722.0\n",
      "episode 11529, reward 1869.0, memory_length 2000, epsilon 0.003136932083818124 total_time 725.0\n",
      "episode 11539, reward 1670.0, memory_length 2000, epsilon 0.0031212865697789398 total_time 730.0\n",
      "episode 11549, reward 1691.0, memory_length 2000, epsilon 0.003105719088066566 total_time 724.0\n",
      "episode 11559, reward 1496.0, memory_length 2000, epsilon 0.0030902292494931483 total_time 723.0\n",
      "episode 11569, reward 1539.0, memory_length 2000, epsilon 0.0030748166668119197 total_time 721.0\n",
      "episode 11579, reward 1324.0, memory_length 2000, epsilon 0.003059480954707508 total_time 724.0\n",
      "episode 11589, reward 1655.0, memory_length 2000, epsilon 0.0030442217297863123 total_time 724.0\n",
      "episode 11599, reward 1962.0, memory_length 2000, epsilon 0.0030290386105669147 total_time 724.0\n",
      "episode 11609, reward 1593.0, memory_length 2000, epsilon 0.0030139312174705443 total_time 721.0\n",
      "episode 11619, reward 1935.0, memory_length 2000, epsilon 0.002998899172811586 total_time 722.0\n",
      "episode 11629, reward 1917.0, memory_length 2000, epsilon 0.0029839421007881407 total_time 721.0\n",
      "episode 11639, reward 1833.0, memory_length 2000, epsilon 0.002969059627472626 total_time 725.0\n",
      "episode 11649, reward 1433.0, memory_length 2000, epsilon 0.00295425138080244 total_time 728.0\n",
      "episode 11659, reward 1520.0, memory_length 2000, epsilon 0.002939516990570641 total_time 724.0\n",
      "episode 11669, reward 2010.0, memory_length 2000, epsilon 0.0029248560884167062 total_time 723.0\n",
      "episode 11679, reward 1620.0, memory_length 2000, epsilon 0.0029102683078173187 total_time 724.0\n",
      "episode 11689, reward 1791.0, memory_length 2000, epsilon 0.0028957532840772028 total_time 726.0\n",
      "episode 11699, reward 1791.0, memory_length 2000, epsilon 0.0028813106543200094 total_time 721.0\n",
      "episode 11709, reward 717.0, memory_length 2000, epsilon 0.002866940057479243 total_time 722.0\n",
      "episode 11719, reward 1679.0, memory_length 2000, epsilon 0.0028526411342892325 total_time 722.0\n",
      "episode 11729, reward 1946.0, memory_length 2000, epsilon 0.0028384135272761526 total_time 725.0\n",
      "episode 11739, reward 1308.0, memory_length 2000, epsilon 0.0028242568807490907 total_time 722.0\n",
      "episode 11749, reward 1904.0, memory_length 2000, epsilon 0.002810170840791145 total_time 728.0\n",
      "episode 11759, reward 1782.0, memory_length 2000, epsilon 0.002796155055250582 total_time 721.0\n",
      "episode 11769, reward 1845.0, memory_length 2000, epsilon 0.0027822091737320334 total_time 732.0\n",
      "episode 11779, reward 1650.0, memory_length 2000, epsilon 0.0027683328475877353 total_time 722.0\n",
      "episode 11789, reward 1902.0, memory_length 2000, epsilon 0.0027545257299088103 total_time 721.0\n",
      "episode 11799, reward 1838.0, memory_length 2000, epsilon 0.002740787475516599 total_time 721.0\n",
      "episode 11809, reward 1207.0, memory_length 2000, epsilon 0.002727117740954022 total_time 728.0\n",
      "episode 11819, reward 1458.0, memory_length 2000, epsilon 0.0027135161844770088 total_time 729.0\n",
      "episode 11829, reward 1490.0, memory_length 2000, epsilon 0.0026999824660459367 total_time 724.0\n",
      "episode 11839, reward 2107.0, memory_length 2000, epsilon 0.0026865162473171398 total_time 724.0\n",
      "episode 11849, reward 1873.0, memory_length 2000, epsilon 0.0026731171916344492 total_time 721.0\n",
      "episode 11859, reward 2001.0, memory_length 2000, epsilon 0.0026597849640207735 total_time 722.0\n",
      "episode 11869, reward 1823.0, memory_length 2000, epsilon 0.00264651923116973 total_time 725.0\n",
      "episode 11879, reward 1559.0, memory_length 2000, epsilon 0.002633319661437305 total_time 723.0\n",
      "episode 11889, reward 1796.0, memory_length 2000, epsilon 0.0026201859248335653 total_time 721.0\n",
      "episode 11899, reward 1542.0, memory_length 2000, epsilon 0.0026071176930144175 total_time 722.0\n",
      "episode 11909, reward 1526.0, memory_length 2000, epsilon 0.0025941146392733823 total_time 724.0\n",
      "episode 11919, reward 1926.0, memory_length 2000, epsilon 0.002581176438533439 total_time 731.0\n",
      "episode 11929, reward 1742.0, memory_length 2000, epsilon 0.0025683027673388957 total_time 728.0\n",
      "episode 11939, reward 1883.0, memory_length 2000, epsilon 0.0025554933038473013 total_time 725.0\n",
      "episode 11949, reward 1982.0, memory_length 2000, epsilon 0.0025427477278214023 total_time 727.0\n",
      "episode 11959, reward 1818.0, memory_length 2000, epsilon 0.0025300657206211337 total_time 725.0\n",
      "episode 11969, reward 1944.0, memory_length 2000, epsilon 0.0025174469651956547 total_time 721.0\n",
      "episode 11979, reward 1565.0, memory_length 2000, epsilon 0.002504891146075421 total_time 721.0\n",
      "episode 11989, reward 1872.0, memory_length 2000, epsilon 0.0024923979493643037 total_time 728.0\n",
      "episode 11999, reward 1331.0, memory_length 2000, epsilon 0.0024799670627317335 total_time 723.0\n",
      "Saving Model 12000\n",
      "episode 12009, reward 2061.0, memory_length 2000, epsilon 0.002467598175404897 total_time 725.0\n",
      "episode 12019, reward 1365.0, memory_length 2000, epsilon 0.002455290978160966 total_time 724.0\n",
      "episode 12029, reward 1935.0, memory_length 2000, epsilon 0.002443045163319369 total_time 724.0\n",
      "episode 12039, reward 1782.0, memory_length 2000, epsilon 0.0024308604247340973 total_time 728.0\n",
      "episode 12049, reward 1870.0, memory_length 2000, epsilon 0.002418736457786051 total_time 724.0\n",
      "episode 12059, reward 1967.0, memory_length 2000, epsilon 0.002406672959375423 total_time 725.0\n",
      "episode 12069, reward 2175.0, memory_length 2000, epsilon 0.00239466962791413 total_time 723.0\n",
      "episode 12079, reward 1580.0, memory_length 2000, epsilon 0.002382726163318257 total_time 728.0\n",
      "episode 12089, reward 1774.0, memory_length 2000, epsilon 0.0023708422670005672 total_time 726.0\n",
      "episode 12099, reward 1670.0, memory_length 2000, epsilon 0.0023590176418630334 total_time 721.0\n",
      "episode 12109, reward 1871.0, memory_length 2000, epsilon 0.002347251992289413 total_time 723.0\n",
      "episode 12119, reward 1792.0, memory_length 2000, epsilon 0.0023355450241378515 total_time 729.0\n",
      "episode 12129, reward 1981.0, memory_length 2000, epsilon 0.002323896444733537 total_time 727.0\n",
      "episode 12139, reward 1422.0, memory_length 2000, epsilon 0.002312305962861375 total_time 728.0\n",
      "episode 12149, reward 1959.0, memory_length 2000, epsilon 0.002300773288758719 total_time 721.0\n",
      "episode 12159, reward 1609.0, memory_length 2000, epsilon 0.0022892981341081143 total_time 722.0\n",
      "episode 12169, reward 1948.0, memory_length 2000, epsilon 0.002277880212030097 total_time 721.0\n",
      "episode 12179, reward 1413.0, memory_length 2000, epsilon 0.00226651923707602 total_time 722.0\n",
      "episode 12189, reward 1764.0, memory_length 2000, epsilon 0.002255214925220918 total_time 723.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 12199, reward 1818.0, memory_length 2000, epsilon 0.0022439669938564056 total_time 724.0\n",
      "episode 12209, reward 1869.0, memory_length 2000, epsilon 0.0022327751617836128 total_time 721.0\n",
      "episode 12219, reward 2050.0, memory_length 2000, epsilon 0.002221639149206155 total_time 723.0\n",
      "episode 12229, reward 1755.0, memory_length 2000, epsilon 0.002210558677723136 total_time 730.0\n",
      "episode 12239, reward 1887.0, memory_length 2000, epsilon 0.0021995334703221957 total_time 723.0\n",
      "episode 12249, reward 1845.0, memory_length 2000, epsilon 0.002188563251372572 total_time 721.0\n",
      "episode 12259, reward 1740.0, memory_length 2000, epsilon 0.002177647746618221 total_time 722.0\n",
      "episode 12269, reward 1658.0, memory_length 2000, epsilon 0.0021667866831709542 total_time 721.0\n",
      "episode 12279, reward 1658.0, memory_length 2000, epsilon 0.00215597978950362 total_time 722.0\n",
      "episode 12289, reward 1674.0, memory_length 2000, epsilon 0.0021452267954433146 total_time 721.0\n",
      "episode 12299, reward 1580.0, memory_length 2000, epsilon 0.002134527432164626 total_time 723.0\n",
      "episode 12309, reward 2165.0, memory_length 2000, epsilon 0.002123881432182913 total_time 725.0\n",
      "episode 12319, reward 2138.0, memory_length 2000, epsilon 0.0021132885293476253 total_time 725.0\n",
      "episode 12329, reward 1799.0, memory_length 2000, epsilon 0.002102748458835638 total_time 721.0\n",
      "episode 12339, reward 2061.0, memory_length 2000, epsilon 0.0020922609571446408 total_time 723.0\n",
      "episode 12349, reward 1998.0, memory_length 2000, epsilon 0.0020818257620865434 total_time 726.0\n",
      "episode 12359, reward 1779.0, memory_length 2000, epsilon 0.0020714426127809273 total_time 723.0\n",
      "episode 12369, reward 2025.0, memory_length 2000, epsilon 0.0020611112496485176 total_time 727.0\n",
      "episode 12379, reward 1589.0, memory_length 2000, epsilon 0.0020508314144046997 total_time 728.0\n",
      "episode 12389, reward 1428.0, memory_length 2000, epsilon 0.002040602850053054 total_time 726.0\n",
      "episode 12399, reward 1413.0, memory_length 2000, epsilon 0.0020304253008789426 total_time 727.0\n",
      "episode 12409, reward 1702.0, memory_length 2000, epsilon 0.0020202985124431047 total_time 725.0\n",
      "episode 12419, reward 1858.0, memory_length 2000, epsilon 0.0020102222315753018 total_time 723.0\n",
      "episode 12429, reward 1593.0, memory_length 2000, epsilon 0.002000196206367988 total_time 726.0\n",
      "episode 12439, reward 1581.0, memory_length 2000, epsilon 0.00199022018617001 total_time 721.0\n",
      "episode 12449, reward 1610.0, memory_length 2000, epsilon 0.0019802939215803434 total_time 723.0\n",
      "episode 12459, reward 1409.0, memory_length 2000, epsilon 0.001970417164441857 total_time 727.0\n",
      "episode 12469, reward 1609.0, memory_length 2000, epsilon 0.0019605896678351075 total_time 723.0\n",
      "episode 12479, reward 1900.0, memory_length 2000, epsilon 0.0019508111860721666 total_time 725.0\n",
      "episode 12489, reward 1535.0, memory_length 2000, epsilon 0.0019410814746904836 total_time 725.0\n",
      "episode 12499, reward 1386.0, memory_length 2000, epsilon 0.001931400290446766 total_time 724.0\n",
      "episode 12509, reward 1539.0, memory_length 2000, epsilon 0.0019217673913109036 total_time 726.0\n",
      "episode 12519, reward 1602.0, memory_length 2000, epsilon 0.0019121825364599159 total_time 729.0\n",
      "episode 12529, reward 1498.0, memory_length 2000, epsilon 0.001902645486271933 total_time 723.0\n",
      "episode 12539, reward 977.0, memory_length 2000, epsilon 0.0018931560023202028 total_time 729.0\n",
      "episode 12549, reward 1868.0, memory_length 2000, epsilon 0.0018837138473671326 total_time 730.0\n",
      "episode 12559, reward 1611.0, memory_length 2000, epsilon 0.0018743187853583552 total_time 721.0\n",
      "episode 12569, reward 1604.0, memory_length 2000, epsilon 0.001864970581416834 total_time 727.0\n",
      "episode 12579, reward 1666.0, memory_length 2000, epsilon 0.0018556690018369825 total_time 724.0\n",
      "episode 12589, reward 1703.0, memory_length 2000, epsilon 0.0018464138140788264 total_time 725.0\n",
      "episode 12599, reward 1690.0, memory_length 2000, epsilon 0.0018372047867621895 total_time 722.0\n",
      "episode 12609, reward 1719.0, memory_length 2000, epsilon 0.0018280416896609096 total_time 726.0\n",
      "episode 12619, reward 1887.0, memory_length 2000, epsilon 0.0018189242936970818 total_time 725.0\n",
      "episode 12629, reward 1765.0, memory_length 2000, epsilon 0.0018098523709353322 total_time 721.0\n",
      "episode 12639, reward 1780.0, memory_length 2000, epsilon 0.0018008256945771176 total_time 721.0\n",
      "episode 12649, reward 1719.0, memory_length 2000, epsilon 0.001791844038955062 total_time 729.0\n",
      "episode 12659, reward 1379.0, memory_length 2000, epsilon 0.0017829071795273058 total_time 723.0\n",
      "episode 12669, reward 1230.0, memory_length 2000, epsilon 0.0017740148928718975 total_time 724.0\n",
      "episode 12679, reward 1937.0, memory_length 2000, epsilon 0.0017651669566812074 total_time 722.0\n",
      "episode 12689, reward 1778.0, memory_length 2000, epsilon 0.0017563631497563707 total_time 722.0\n",
      "episode 12699, reward 1607.0, memory_length 2000, epsilon 0.0017476032520017547 total_time 734.0\n",
      "episode 12709, reward 1817.0, memory_length 2000, epsilon 0.0017388870444194602 total_time 723.0\n",
      "episode 12719, reward 1771.0, memory_length 2000, epsilon 0.001730214309103843 total_time 723.0\n",
      "episode 12729, reward 699.0, memory_length 2000, epsilon 0.0017215848292360676 total_time 724.0\n",
      "episode 12739, reward 1796.0, memory_length 2000, epsilon 0.0017129983890786904 total_time 726.0\n",
      "episode 12749, reward 1806.0, memory_length 2000, epsilon 0.001704454773970259 total_time 724.0\n",
      "episode 12759, reward 1384.0, memory_length 2000, epsilon 0.0016959537703199504 total_time 723.0\n",
      "episode 12769, reward 1798.0, memory_length 2000, epsilon 0.0016874951656022312 total_time 721.0\n",
      "episode 12779, reward 907.0, memory_length 2000, epsilon 0.001679078748351542 total_time 723.0\n",
      "episode 12789, reward 1827.0, memory_length 2000, epsilon 0.001670704308157014 total_time 725.0\n",
      "episode 12799, reward 1997.0, memory_length 2000, epsilon 0.0016623716356572059 total_time 723.0\n",
      "episode 12809, reward 2193.0, memory_length 2000, epsilon 0.0016540805225348694 total_time 722.0\n",
      "episode 12819, reward 1911.0, memory_length 2000, epsilon 0.0016458307615117482 total_time 722.0\n",
      "episode 12829, reward 1842.0, memory_length 2000, epsilon 0.001637622146343385 total_time 725.0\n",
      "episode 12839, reward 2090.0, memory_length 2000, epsilon 0.001629454471813973 total_time 722.0\n",
      "episode 12849, reward 2174.0, memory_length 2000, epsilon 0.0016213275337312245 total_time 730.0\n",
      "episode 12859, reward 1817.0, memory_length 2000, epsilon 0.001613241128921263 total_time 721.0\n",
      "episode 12869, reward 1940.0, memory_length 2000, epsilon 0.0016051950552235475 total_time 723.0\n",
      "episode 12879, reward 1736.0, memory_length 2000, epsilon 0.0015971891114858168 total_time 723.0\n",
      "episode 12889, reward 1495.0, memory_length 2000, epsilon 0.0015892230975590588 total_time 724.0\n",
      "episode 12899, reward 1017.0, memory_length 2000, epsilon 0.0015812968142925135 total_time 725.0\n",
      "episode 12909, reward 1890.0, memory_length 2000, epsilon 0.0015734100635286844 total_time 724.0\n",
      "episode 12919, reward 1954.0, memory_length 2000, epsilon 0.0015655626480983924 total_time 728.0\n",
      "episode 12929, reward 1755.0, memory_length 2000, epsilon 0.0015577543718158424 total_time 721.0\n",
      "episode 12939, reward 1971.0, memory_length 2000, epsilon 0.001549985039473721 total_time 725.0\n",
      "episode 12949, reward 2095.0, memory_length 2000, epsilon 0.0015422544568383146 total_time 726.0\n",
      "episode 12959, reward 1657.0, memory_length 2000, epsilon 0.0015345624306446553 total_time 721.0\n",
      "episode 12969, reward 1973.0, memory_length 2000, epsilon 0.0015269087685916875 total_time 726.0\n",
      "episode 12979, reward 2115.0, memory_length 2000, epsilon 0.0015192932793374593 total_time 721.0\n",
      "episode 12989, reward 1905.0, memory_length 2000, epsilon 0.001511715772494346 total_time 723.0\n",
      "episode 12999, reward 1811.0, memory_length 2000, epsilon 0.0015041760586242804 total_time 721.0\n",
      "Saving Model 13000\n",
      "episode 13009, reward 1482.0, memory_length 2000, epsilon 0.0014966739492340226 total_time 721.0\n",
      "episode 13019, reward 1962.0, memory_length 2000, epsilon 0.0014892092567704478 total_time 723.0\n",
      "episode 13029, reward 2009.0, memory_length 2000, epsilon 0.0014817817946158553 total_time 724.0\n",
      "episode 13039, reward 1505.0, memory_length 2000, epsilon 0.0014743913770833043 total_time 722.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 13049, reward 1788.0, memory_length 2000, epsilon 0.0014670378194119717 total_time 722.0\n",
      "episode 13059, reward 1919.0, memory_length 2000, epsilon 0.0014597209377625313 total_time 723.0\n",
      "episode 13069, reward 1926.0, memory_length 2000, epsilon 0.0014524405492125636 total_time 721.0\n",
      "episode 13079, reward 1810.0, memory_length 2000, epsilon 0.0014451964717519742 total_time 723.0\n",
      "episode 13089, reward 1747.0, memory_length 2000, epsilon 0.0014379885242784493 total_time 721.0\n",
      "episode 13099, reward 1819.0, memory_length 2000, epsilon 0.0014308165265929267 total_time 725.0\n",
      "episode 13109, reward 1927.0, memory_length 2000, epsilon 0.0014236802993950906 total_time 724.0\n",
      "episode 13119, reward 1773.0, memory_length 2000, epsilon 0.0014165796642788893 total_time 721.0\n",
      "episode 13129, reward 1778.0, memory_length 2000, epsilon 0.0014095144437280755 total_time 727.0\n",
      "episode 13139, reward 1877.0, memory_length 2000, epsilon 0.0014024844611117656 total_time 727.0\n",
      "episode 13149, reward 1909.0, memory_length 2000, epsilon 0.0013954895406800313 total_time 726.0\n",
      "episode 13159, reward 1316.0, memory_length 2000, epsilon 0.0013885295075594956 total_time 723.0\n",
      "episode 13169, reward 1580.0, memory_length 2000, epsilon 0.001381604187748968 total_time 725.0\n",
      "episode 13179, reward 1710.0, memory_length 2000, epsilon 0.001374713408115093 total_time 730.0\n",
      "episode 13189, reward 1456.0, memory_length 2000, epsilon 0.0013678569963880207 total_time 722.0\n",
      "episode 13199, reward 680.0, memory_length 2000, epsilon 0.0013610347811571003 total_time 729.0\n",
      "episode 13209, reward 1923.0, memory_length 2000, epsilon 0.0013542465918665965 total_time 723.0\n",
      "episode 13219, reward 965.0, memory_length 2000, epsilon 0.0013474922588114229 total_time 721.0\n",
      "episode 13229, reward 1859.0, memory_length 2000, epsilon 0.0013407716131329003 total_time 723.0\n",
      "episode 13239, reward 1756.0, memory_length 2000, epsilon 0.0013340844868145393 total_time 724.0\n",
      "episode 13249, reward 1575.0, memory_length 2000, epsilon 0.001327430712677832 total_time 721.0\n",
      "episode 13259, reward 1949.0, memory_length 2000, epsilon 0.001320810124378079 total_time 722.0\n",
      "episode 13269, reward 1938.0, memory_length 2000, epsilon 0.0013142225564002276 total_time 725.0\n",
      "episode 13279, reward 1886.0, memory_length 2000, epsilon 0.0013076678440547354 total_time 725.0\n",
      "episode 13289, reward 1485.0, memory_length 2000, epsilon 0.0013011458234734523 total_time 721.0\n",
      "episode 13299, reward 1911.0, memory_length 2000, epsilon 0.001294656331605524 total_time 721.0\n",
      "episode 13309, reward 1706.0, memory_length 2000, epsilon 0.001288199206213315 total_time 725.0\n",
      "episode 13319, reward 1451.0, memory_length 2000, epsilon 0.001281774285868356 total_time 724.0\n",
      "episode 13329, reward 2073.0, memory_length 2000, epsilon 0.0012753814099473028 total_time 722.0\n",
      "episode 13339, reward 1555.0, memory_length 2000, epsilon 0.0012690204186279247 total_time 721.0\n",
      "episode 13349, reward 1587.0, memory_length 2000, epsilon 0.001262691152885107 total_time 724.0\n",
      "episode 13359, reward 1793.0, memory_length 2000, epsilon 0.0012563934544868767 total_time 721.0\n",
      "episode 13369, reward 1709.0, memory_length 2000, epsilon 0.001250127165990446 total_time 721.0\n",
      "episode 13379, reward 2008.0, memory_length 2000, epsilon 0.0012438921307382756 total_time 728.0\n",
      "episode 13389, reward 1809.0, memory_length 2000, epsilon 0.0012376881928541587 total_time 727.0\n",
      "episode 13399, reward 1347.0, memory_length 2000, epsilon 0.0012315151972393274 total_time 724.0\n",
      "episode 13409, reward 1336.0, memory_length 2000, epsilon 0.0012253729895685685 total_time 723.0\n",
      "episode 13419, reward 1960.0, memory_length 2000, epsilon 0.0012192614162863703 total_time 722.0\n",
      "episode 13429, reward 1451.0, memory_length 2000, epsilon 0.0012131803246030824 total_time 723.0\n",
      "episode 13439, reward 1483.0, memory_length 2000, epsilon 0.0012071295624910964 total_time 721.0\n",
      "episode 13449, reward 1428.0, memory_length 2000, epsilon 0.0012011089786810438 total_time 726.0\n",
      "episode 13459, reward 1810.0, memory_length 2000, epsilon 0.001195118422658016 total_time 723.0\n",
      "episode 13469, reward 1488.0, memory_length 2000, epsilon 0.0011891577446578006 total_time 722.0\n",
      "episode 13479, reward 1855.0, memory_length 2000, epsilon 0.001183226795663136 total_time 726.0\n",
      "episode 13489, reward 1617.0, memory_length 2000, epsilon 0.0011773254273999905 total_time 725.0\n",
      "episode 13499, reward 1935.0, memory_length 2000, epsilon 0.0011714534923338489 total_time 722.0\n",
      "episode 13509, reward 1616.0, memory_length 2000, epsilon 0.0011656108436660288 total_time 728.0\n",
      "episode 13519, reward 2068.0, memory_length 2000, epsilon 0.0011597973353300096 total_time 721.0\n",
      "episode 13529, reward 1776.0, memory_length 2000, epsilon 0.0011540128219877798 total_time 727.0\n",
      "episode 13539, reward 1485.0, memory_length 2000, epsilon 0.0011482571590262043 total_time 723.0\n",
      "episode 13549, reward 1719.0, memory_length 2000, epsilon 0.0011425302025534097 total_time 722.0\n",
      "episode 13559, reward 1717.0, memory_length 2000, epsilon 0.0011368318093951848 total_time 722.0\n",
      "episode 13569, reward 1897.0, memory_length 2000, epsilon 0.001131161837091406 total_time 723.0\n",
      "episode 13579, reward 1964.0, memory_length 2000, epsilon 0.001125520143892469 total_time 725.0\n",
      "episode 13589, reward 2089.0, memory_length 2000, epsilon 0.00111990658875575 total_time 724.0\n",
      "episode 13599, reward 1443.0, memory_length 2000, epsilon 0.0011143210313420788 total_time 721.0\n",
      "episode 13609, reward 2058.0, memory_length 2000, epsilon 0.0011087633320122285 total_time 725.0\n",
      "episode 13619, reward 1624.0, memory_length 2000, epsilon 0.0011032333518234269 total_time 725.0\n",
      "episode 13629, reward 2007.0, memory_length 2000, epsilon 0.001097730952525881 total_time 724.0\n",
      "episode 13639, reward 1746.0, memory_length 2000, epsilon 0.0010922559965593204 total_time 727.0\n",
      "episode 13649, reward 2195.0, memory_length 2000, epsilon 0.0010868083470495634 total_time 721.0\n",
      "episode 13659, reward 1673.0, memory_length 2000, epsilon 0.0010813878678050874 total_time 721.0\n",
      "episode 13669, reward 1994.0, memory_length 2000, epsilon 0.0010759944233136285 total_time 729.0\n",
      "episode 13679, reward 1404.0, memory_length 2000, epsilon 0.0010706278787387942 total_time 723.0\n",
      "episode 13689, reward 1982.0, memory_length 2000, epsilon 0.0010652880999166901 total_time 726.0\n",
      "episode 13699, reward 1782.0, memory_length 2000, epsilon 0.001059974953352568 total_time 723.0\n",
      "episode 13709, reward 1773.0, memory_length 2000, epsilon 0.0010546883062174865 total_time 721.0\n",
      "episode 13719, reward 854.0, memory_length 2000, epsilon 0.0010494280263449924 total_time 721.0\n",
      "episode 13729, reward 1279.0, memory_length 2000, epsilon 0.0010441939822278133 total_time 725.0\n",
      "episode 13739, reward 2104.0, memory_length 2000, epsilon 0.0010389860430145765 total_time 723.0\n",
      "episode 13749, reward 1549.0, memory_length 2000, epsilon 0.0010338040785065287 total_time 725.0\n",
      "episode 13759, reward 1374.0, memory_length 2000, epsilon 0.0010286479591542876 total_time 733.0\n",
      "episode 13769, reward 1728.0, memory_length 2000, epsilon 0.0010235175560546008 total_time 724.0\n",
      "episode 13779, reward 1956.0, memory_length 2000, epsilon 0.0010184127409471235 total_time 731.0\n",
      "episode 13789, reward 1715.0, memory_length 2000, epsilon 0.0010133333862112125 total_time 727.0\n",
      "episode 13799, reward 1962.0, memory_length 2000, epsilon 0.0010082793648627346 total_time 726.0\n",
      "episode 13809, reward 1260.0, memory_length 2000, epsilon 0.0010032505505508918 total_time 722.0\n",
      "episode 13819, reward 1785.0, memory_length 2000, epsilon 0.0009982468175550663 total_time 724.0\n",
      "episode 13829, reward 1634.0, memory_length 2000, epsilon 0.000993268040781672 total_time 730.0\n",
      "episode 13839, reward 1926.0, memory_length 2000, epsilon 0.0009883140957610299 total_time 721.0\n",
      "episode 13849, reward 1893.0, memory_length 2000, epsilon 0.0009833848586442563 total_time 722.0\n",
      "episode 13859, reward 2306.0, memory_length 2000, epsilon 0.000978480206200167 total_time 727.0\n",
      "episode 13869, reward 1832.0, memory_length 2000, epsilon 0.0009736000158121954 total_time 727.0\n",
      "episode 13879, reward 1620.0, memory_length 2000, epsilon 0.0009687441654753273 total_time 721.0\n",
      "episode 13889, reward 1965.0, memory_length 2000, epsilon 0.0009639125337930508 total_time 722.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 13899, reward 1895.0, memory_length 2000, epsilon 0.0009591049999743237 total_time 722.0\n",
      "episode 13909, reward 1815.0, memory_length 2000, epsilon 0.0009543214438305494 total_time 724.0\n",
      "episode 13919, reward 1598.0, memory_length 2000, epsilon 0.0009495617457725752 total_time 722.0\n",
      "episode 13929, reward 1826.0, memory_length 2000, epsilon 0.0009448257868077017 total_time 724.0\n",
      "episode 13939, reward 1680.0, memory_length 2000, epsilon 0.0009401134485367081 total_time 722.0\n",
      "episode 13949, reward 1342.0, memory_length 2000, epsilon 0.0009354246131508923 total_time 723.0\n",
      "episode 13959, reward 1756.0, memory_length 2000, epsilon 0.0009307591634291251 total_time 723.0\n",
      "episode 13969, reward 1742.0, memory_length 2000, epsilon 0.0009261169827349209 total_time 724.0\n",
      "episode 13979, reward 1715.0, memory_length 2000, epsilon 0.0009214979550135194 total_time 723.0\n",
      "episode 13989, reward 1959.0, memory_length 2000, epsilon 0.0009169019647889888 total_time 725.0\n",
      "episode 13999, reward 1811.0, memory_length 2000, epsilon 0.0009123288971613334 total_time 721.0\n",
      "Saving Model 14000\n",
      "episode 14009, reward 1816.0, memory_length 2000, epsilon 0.0009077786378036242 total_time 725.0\n",
      "episode 14019, reward 2052.0, memory_length 2000, epsilon 0.0009032510729591402 total_time 729.0\n",
      "episode 14029, reward 1919.0, memory_length 2000, epsilon 0.0008987460894385246 total_time 723.0\n",
      "episode 14039, reward 1389.0, memory_length 2000, epsilon 0.0008942635746169547 total_time 723.0\n",
      "episode 14049, reward 1827.0, memory_length 2000, epsilon 0.0008898034164313264 total_time 727.0\n",
      "episode 14059, reward 2027.0, memory_length 2000, epsilon 0.0008853655033774521 total_time 724.0\n",
      "episode 14069, reward 2044.0, memory_length 2000, epsilon 0.0008809497245072759 total_time 731.0\n",
      "episode 14079, reward 1326.0, memory_length 2000, epsilon 0.0008765559694260952 total_time 722.0\n",
      "episode 14089, reward 1838.0, memory_length 2000, epsilon 0.000872184128289804 total_time 724.0\n",
      "episode 14099, reward 2230.0, memory_length 2000, epsilon 0.0008678340918021465 total_time 726.0\n",
      "episode 14109, reward 1821.0, memory_length 2000, epsilon 0.0008635057512119837 total_time 721.0\n",
      "episode 14119, reward 1738.0, memory_length 2000, epsilon 0.0008591989983105755 total_time 724.0\n",
      "episode 14129, reward 2086.0, memory_length 2000, epsilon 0.0008549137254288751 total_time 726.0\n",
      "episode 14139, reward 2017.0, memory_length 2000, epsilon 0.0008506498254348365 total_time 729.0\n",
      "episode 14149, reward 1316.0, memory_length 2000, epsilon 0.0008464071917307392 total_time 722.0\n",
      "episode 14159, reward 1802.0, memory_length 2000, epsilon 0.0008421857182505188 total_time 723.0\n",
      "episode 14169, reward 1670.0, memory_length 2000, epsilon 0.0008379852994571187 total_time 724.0\n",
      "episode 14179, reward 1868.0, memory_length 2000, epsilon 0.00083380583033985 total_time 728.0\n",
      "episode 14189, reward 1468.0, memory_length 2000, epsilon 0.0008296472064117673 total_time 729.0\n",
      "episode 14199, reward 1963.0, memory_length 2000, epsilon 0.0008255093237070557 total_time 724.0\n",
      "episode 14209, reward 2247.0, memory_length 2000, epsilon 0.0008213920787784321 total_time 724.0\n",
      "episode 14219, reward 1893.0, memory_length 2000, epsilon 0.0008172953686945588 total_time 726.0\n",
      "episode 14229, reward 2080.0, memory_length 2000, epsilon 0.0008132190910374698 total_time 723.0\n",
      "episode 14239, reward 1811.0, memory_length 2000, epsilon 0.0008091631439000125 total_time 722.0\n",
      "episode 14249, reward 1683.0, memory_length 2000, epsilon 0.0008051274258832966 total_time 721.0\n",
      "episode 14259, reward 1833.0, memory_length 2000, epsilon 0.0008011118360941616 total_time 723.0\n",
      "episode 14269, reward 1371.0, memory_length 2000, epsilon 0.0007971162741426536 total_time 724.0\n",
      "episode 14279, reward 1409.0, memory_length 2000, epsilon 0.0007931406401395156 total_time 724.0\n",
      "episode 14289, reward 2061.0, memory_length 2000, epsilon 0.0007891848346936906 total_time 723.0\n",
      "episode 14299, reward 1807.0, memory_length 2000, epsilon 0.0007852487589098364 total_time 726.0\n",
      "episode 14309, reward 1909.0, memory_length 2000, epsilon 0.0007813323143858526 total_time 723.0\n",
      "episode 14319, reward 1904.0, memory_length 2000, epsilon 0.0007774354032104235 total_time 727.0\n",
      "episode 14329, reward 2211.0, memory_length 2000, epsilon 0.0007735579279605663 total_time 725.0\n",
      "episode 14339, reward 1433.0, memory_length 2000, epsilon 0.0007696997916991974 total_time 725.0\n",
      "episode 14349, reward 1792.0, memory_length 2000, epsilon 0.0007658608979727096 total_time 726.0\n",
      "episode 14359, reward 1872.0, memory_length 2000, epsilon 0.0007620411508085598 total_time 721.0\n",
      "episode 14369, reward 1581.0, memory_length 2000, epsilon 0.00075824045471287 total_time 721.0\n",
      "episode 14379, reward 1740.0, memory_length 2000, epsilon 0.0007544587146680395 total_time 721.0\n",
      "episode 14389, reward 1945.0, memory_length 2000, epsilon 0.0007506958361303699 total_time 727.0\n",
      "episode 14399, reward 2073.0, memory_length 2000, epsilon 0.0007469517250277031 total_time 725.0\n",
      "episode 14409, reward 1719.0, memory_length 2000, epsilon 0.0007432262877570657 total_time 724.0\n",
      "episode 14419, reward 1716.0, memory_length 2000, epsilon 0.0007395194311823318 total_time 721.0\n",
      "episode 14429, reward 1650.0, memory_length 2000, epsilon 0.0007358310626318943 total_time 725.0\n",
      "episode 14439, reward 1734.0, memory_length 2000, epsilon 0.0007321610898963471 total_time 725.0\n",
      "episode 14449, reward 1872.0, memory_length 2000, epsilon 0.0007285094212261808 total_time 725.0\n",
      "episode 14459, reward 1792.0, memory_length 2000, epsilon 0.0007248759653294883 total_time 724.0\n",
      "episode 14469, reward 1369.0, memory_length 2000, epsilon 0.0007212606313696831 total_time 730.0\n",
      "episode 14479, reward 1825.0, memory_length 2000, epsilon 0.0007176633289632272 total_time 724.0\n",
      "episode 14489, reward 2152.0, memory_length 2000, epsilon 0.0007140839681773742 total_time 725.0\n",
      "episode 14499, reward 2088.0, memory_length 2000, epsilon 0.0007105224595279177 total_time 724.0\n",
      "episode 14509, reward 1757.0, memory_length 2000, epsilon 0.0007069787139769558 total_time 724.0\n",
      "episode 14519, reward 1175.0, memory_length 2000, epsilon 0.0007034526429306651 total_time 732.0\n",
      "episode 14529, reward 1834.0, memory_length 2000, epsilon 0.0006999441582370858 total_time 721.0\n",
      "episode 14539, reward 1382.0, memory_length 2000, epsilon 0.0006964531721839179 total_time 723.0\n",
      "episode 14549, reward 1908.0, memory_length 2000, epsilon 0.0006929795974963283 total_time 726.0\n",
      "episode 14559, reward 1402.0, memory_length 2000, epsilon 0.0006895233473347682 total_time 724.0\n",
      "episode 14569, reward 1572.0, memory_length 2000, epsilon 0.0006860843352928048 total_time 721.0\n",
      "episode 14579, reward 1921.0, memory_length 2000, epsilon 0.0006826624753949572 total_time 724.0\n",
      "episode 14589, reward 1999.0, memory_length 2000, epsilon 0.0006792576820945501 total_time 724.0\n",
      "episode 14599, reward 1664.0, memory_length 2000, epsilon 0.0006758698702715732 total_time 721.0\n",
      "episode 14609, reward 1404.0, memory_length 2000, epsilon 0.0006724989552305546 total_time 721.0\n",
      "episode 14619, reward 1835.0, memory_length 2000, epsilon 0.0006691448526984429 total_time 727.0\n",
      "episode 14629, reward 1603.0, memory_length 2000, epsilon 0.0006658074788224999 total_time 726.0\n",
      "episode 14639, reward 1465.0, memory_length 2000, epsilon 0.0006624867501682045 total_time 721.0\n",
      "episode 14649, reward 1990.0, memory_length 2000, epsilon 0.0006591825837171684 total_time 723.0\n",
      "episode 14659, reward 1751.0, memory_length 2000, epsilon 0.0006558948968650576 total_time 721.0\n",
      "episode 14669, reward 1324.0, memory_length 2000, epsilon 0.0006526236074195298 total_time 724.0\n",
      "episode 14679, reward 1511.0, memory_length 2000, epsilon 0.0006493686335981781 total_time 722.0\n",
      "episode 14689, reward 1567.0, memory_length 2000, epsilon 0.0006461298940264879 total_time 724.0\n",
      "episode 14699, reward 1743.0, memory_length 2000, epsilon 0.0006429073077358008 total_time 721.0\n",
      "episode 14709, reward 1458.0, memory_length 2000, epsilon 0.000639700794161292 total_time 723.0\n",
      "episode 14719, reward 1896.0, memory_length 2000, epsilon 0.0006365102731399544 total_time 722.0\n",
      "episode 14729, reward 1712.0, memory_length 2000, epsilon 0.0006333356649085975 total_time 724.0\n",
      "episode 14739, reward 1517.0, memory_length 2000, epsilon 0.0006301768901018495 total_time 721.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 14749, reward 1647.0, memory_length 2000, epsilon 0.000627033869750176 total_time 731.0\n",
      "episode 14759, reward 1477.0, memory_length 2000, epsilon 0.0006239065252779041 total_time 731.0\n",
      "episode 14769, reward 1648.0, memory_length 2000, epsilon 0.0006207947785012593 total_time 721.0\n",
      "episode 14779, reward 1717.0, memory_length 2000, epsilon 0.0006176985516264101 total_time 721.0\n",
      "episode 14789, reward 1785.0, memory_length 2000, epsilon 0.0006146177672475235 total_time 721.0\n",
      "episode 14799, reward 1735.0, memory_length 2000, epsilon 0.0006115523483448293 total_time 723.0\n",
      "episode 14809, reward 1657.0, memory_length 2000, epsilon 0.0006085022182826951 total_time 731.0\n",
      "episode 14819, reward 1242.0, memory_length 2000, epsilon 0.0006054673008077113 total_time 726.0\n",
      "episode 14829, reward 2244.0, memory_length 2000, epsilon 0.0006024475200467823 total_time 721.0\n",
      "episode 14839, reward 1688.0, memory_length 2000, epsilon 0.0005994428005052322 total_time 723.0\n",
      "episode 14849, reward 1191.0, memory_length 2000, epsilon 0.0005964530670649156 total_time 727.0\n",
      "episode 14859, reward 1647.0, memory_length 2000, epsilon 0.0005934782449823409 total_time 721.0\n",
      "episode 14869, reward 1558.0, memory_length 2000, epsilon 0.0005905182598868013 total_time 726.0\n",
      "episode 14879, reward 1935.0, memory_length 2000, epsilon 0.0005875730377785148 total_time 726.0\n",
      "episode 14889, reward 1828.0, memory_length 2000, epsilon 0.0005846425050267752 total_time 724.0\n",
      "episode 14899, reward 1531.0, memory_length 2000, epsilon 0.0005817265883681118 total_time 729.0\n",
      "episode 14909, reward 1797.0, memory_length 2000, epsilon 0.000578825214904456 total_time 723.0\n",
      "episode 14919, reward 1296.0, memory_length 2000, epsilon 0.00057593831210132 total_time 721.0\n",
      "episode 14929, reward 1659.0, memory_length 2000, epsilon 0.0005730658077859833 total_time 725.0\n",
      "episode 14939, reward 1949.0, memory_length 2000, epsilon 0.0005702076301456883 total_time 725.0\n",
      "episode 14949, reward 1752.0, memory_length 2000, epsilon 0.0005673637077258456 total_time 723.0\n",
      "episode 14959, reward 1682.0, memory_length 2000, epsilon 0.0005645339694282461 total_time 721.0\n",
      "episode 14969, reward 2120.0, memory_length 2000, epsilon 0.0005617183445092846 total_time 727.0\n",
      "episode 14979, reward 1922.0, memory_length 2000, epsilon 0.0005589167625781924 total_time 727.0\n",
      "episode 14989, reward 1643.0, memory_length 2000, epsilon 0.0005561291535952752 total_time 725.0\n",
      "episode 14999, reward 1834.0, memory_length 2000, epsilon 0.0005533554478701629 total_time 725.0\n",
      "46547.702102184296\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "score_tracked = []\n",
    "\n",
    "for episode in range(n_episodes):\n",
    "\n",
    "    done = False\n",
    "    score = 0\n",
    "    track_reward = False\n",
    "\n",
    "    # reset at the start of each episode\n",
    "    env = CabDriver()\n",
    "    action_space, state_space, state = env.reset()\n",
    "    # Save the initial state so that reward can be tracked if initial state is [0,0,0]\n",
    "    initial_state = env.state_init\n",
    "\n",
    "\n",
    "    total_time = 0  # Total time driver rode in this episode\n",
    "    while not done:\n",
    "        # 1. Get a list of the ride requests driver got.\n",
    "        possible_actions_indices, actions = env.requests(state)\n",
    "        # 2. Pick epsilon-greedy action from possible actions for the current state.\n",
    "        action = agent.get_action(state, possible_actions_indices, actions)\n",
    "\n",
    "        # 3. Evaluate your reward and next state\n",
    "        reward, next_state, step_time = env.step(state, env.action_space[action], Time_matrix)\n",
    "        # 4. Total time driver rode in this episode\n",
    "        total_time += step_time\n",
    "        if (total_time > episode_time):\n",
    "            # if ride does not complete in stipu;ated time skip\n",
    "            # it and move to next episode.\n",
    "            done = True\n",
    "        else:\n",
    "            # 5. Append the experience to the memory\n",
    "            agent.append_sample(state, action, reward, next_state, done)\n",
    "            # 6. Train the model by calling function agent.train_model\n",
    "            agent.train_model()\n",
    "            # 7. Keep a track of rewards, Q-values, loss\n",
    "            score += reward\n",
    "            state = next_state\n",
    "\n",
    "    # store total reward obtained in this episode\n",
    "    rewards_per_episode.append(score)\n",
    "    episodes.append(episode)\n",
    "    \n",
    "\n",
    "    # epsilon decay\n",
    "    agent.epsilon = (1 - 0.00001) * np.exp(agent.epsilon_decay * episode)\n",
    "\n",
    "    # every 10 episodes:\n",
    "    if ((episode + 1) % 10 == 0):\n",
    "        print(\"episode {0}, reward {1}, memory_length {2}, epsilon {3} total_time {4}\".format(episode,\n",
    "                                                                         score,\n",
    "                                                                         len(agent.memory),\n",
    "                                                                         agent.epsilon, total_time))\n",
    "    # Save the Q_value of the state, action pair we are tracking\n",
    "    if ((episode + 1) % 5 == 0):\n",
    "        agent.save_tracking_states()\n",
    "\n",
    "    # Total rewards per episode\n",
    "    score_tracked.append(score)\n",
    "\n",
    "    if(episode % 1000 == 0):\n",
    "        print(\"Saving Model {}\".format(episode))\n",
    "        agent.save(name=\"model_weights.pkl\")\n",
    "    \n",
    "elapsed_time = time.time() - start_time\n",
    "print(elapsed_time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The 'total_time' above includes the 'last ride' time also in each episode. Although it exceeds 24*30 = 720, our code drops the last ride from the replay buffer. So the total ride time per episode is limited to < 720"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.save(name=\"model_weights.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracking Convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.states_tracked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_tracked_sample = [agent.states_tracked[i] for i in range(len(agent.states_tracked)) if agent.states_tracked[i] < 1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Plot the Q-Value convergence for state action pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(0, figsize=(16,7))\n",
    "plt.title('Q_value for state [0,0,0]  action (0,2)')\n",
    "xaxis = np.asarray(range(0, len(agent.states_tracked)))\n",
    "plt.semilogy(xaxis,np.asarray(agent.states_tracked))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We are using log scale because the initial q_values are way to high compared to the steady state value (around 600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Track rewards per episode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_tracked_sample = [score_tracked[i] for i in range(len(score_tracked)) if (i % 4 == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(0, figsize=(16,7))\n",
    "plt.title('Rewards per episode')\n",
    "xaxis = np.asarray(range(0, len(score_tracked_sample)))\n",
    "plt.plot(xaxis,np.asarray(score_tracked_sample))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can see from the above plot that the rewards converge at around 1500. Since the initial state is picked to be random for each episode, some initial states may be less rewarding than others inherently regardless of the model quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Epsilon-decay sample function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Try building a similar epsilon-decay function for your model.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "time = np.arange(0,15000)\n",
    "epsilon = []\n",
    "for i in range(0,15000):\n",
    "    epsilon.append((1 - 0.00001) * np.exp(-0.0005 * i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(time, epsilon)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
